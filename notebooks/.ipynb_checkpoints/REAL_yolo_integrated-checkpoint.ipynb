{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b4726e9-f6fa-4989-8718-bded6c32ccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "import shutil\n",
    "import yaml\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4503e61-dc00-480c-9bbd-6135f89ef3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> 80\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolo11x.pt\") # 원하는 크기 모델 입력(n, s, m, l, x 등 원하는 모델을 로드함)\n",
    "print(type(model.names),len(model.names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9987abb3-b494-4347-b1fc-b2093688d508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/3 /app/yolo_structure/test/Suwon_CH01_20200721_1500_TUE_9m_NH_highway_TW5_sunny_FHD_013.png: 640x384 14 cars, 8 trucks, 111.4ms\n",
      "image 2/3 /app/yolo_structure/test/hh_dash.jpg: 384x640 1 person, 7 cars, 1 truck, 1 handbag, 107.6ms\n",
      "image 3/3 /app/yolo_structure/test/people_street.jpeg: 384x640 5 persons, 1 car, 1 motorcycle, 2 backpacks, 1 handbag, 1 cell phone, 101.6ms\n",
      "Speed: 0.7ms preprocess, 106.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "curr_dir = os.getcwd()\n",
    "test_loc = os.path.join(curr_dir,\"test\")\n",
    "results = model.predict(source = test_loc,save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7177d16c-2060-464b-ad58-de53c4dc95af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = os.path.join(curr_dir, \"my_test_model.pt\")  # 모델 저장 경로\n",
    "detailed_model = YOLO(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ee3769f-744a-4742-8a50-fbd9f9911719",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/3 /app/yolo_structure/test/Suwon_CH01_20200721_1500_TUE_9m_NH_highway_TW5_sunny_FHD_013.png: 640x384 14 cars, 8 trucks, 22.9ms\n",
      "image 2/3 /app/yolo_structure/test/hh_dash.jpg: 384x640 1 person, 7 cars, 1 truck, 1 handbag, 18.4ms\n",
      "image 3/3 /app/yolo_structure/test/people_street.jpeg: 384x640 5 persons, 1 car, 1 motorcycle, 2 backpacks, 1 handbag, 1 cell phone, 16.0ms\n",
      "Speed: 1.6ms preprocess, 19.1ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict35\u001b[0m\n",
      "/app/yolo_structure/test/Suwon_CH01_20200721_1500_TUE_9m_NH_highway_TW5_sunny_FHD_013.png car\n",
      "/app/yolo_structure/crops/car_crop_000.jpg\n",
      "\n",
      "image 1/1 /app/yolo_structure/crops/car_crop_000.jpg: 352x416 (no detections), 18.4ms\n",
      "Speed: 2.3ms preprocess, 18.4ms inference, 4.5ms postprocess per image at shape (1, 3, 352, 416)\n",
      ">>>>>>>>>>>>>>>>>>>>>No object /app/yolo_structure/crops/car_crop_000.jpg\n",
      "/app/yolo_structure/test/Suwon_CH01_20200721_1500_TUE_9m_NH_highway_TW5_sunny_FHD_013.png car\n",
      "/app/yolo_structure/crops/car_crop_001.jpg\n",
      "\n",
      "image 1/1 /app/yolo_structure/crops/car_crop_001.jpg: 224x416 (no detections), 15.4ms\n",
      "Speed: 1.6ms preprocess, 15.4ms inference, 4.5ms postprocess per image at shape (1, 3, 224, 416)\n",
      ">>>>>>>>>>>>>>>>>>>>>No object /app/yolo_structure/crops/car_crop_001.jpg\n",
      "/app/yolo_structure/test/Suwon_CH01_20200721_1500_TUE_9m_NH_highway_TW5_sunny_FHD_013.png car\n",
      "/app/yolo_structure/crops/car_crop_002.jpg\n",
      "\n",
      "image 1/1 /app/yolo_structure/crops/car_crop_002.jpg: 384x416 (no detections), 18.6ms\n",
      "Speed: 0.5ms preprocess, 18.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 416)\n",
      ">>>>>>>>>>>>>>>>>>>>>No object /app/yolo_structure/crops/car_crop_002.jpg\n",
      "/app/yolo_structure/test/Suwon_CH01_20200721_1500_TUE_9m_NH_highway_TW5_sunny_FHD_013.png car\n",
      "/app/yolo_structure/crops/car_crop_003.jpg\n",
      "\n",
      "image 1/1 /app/yolo_structure/crops/car_crop_003.jpg: 384x416 (no detections), 11.7ms\n",
      "Speed: 0.8ms preprocess, 11.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 416)\n",
      ">>>>>>>>>>>>>>>>>>>>>No object /app/yolo_structure/crops/car_crop_003.jpg\n",
      "/app/yolo_structure/test/Suwon_CH01_20200721_1500_TUE_9m_NH_highway_TW5_sunny_FHD_013.png car\n",
      "/app/yolo_structure/crops/car_crop_004.jpg\n",
      "\n",
      "image 1/1 /app/yolo_structure/crops/car_crop_004.jpg: 320x416 (no detections), 18.8ms\n",
      "Speed: 3.0ms preprocess, 18.8ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      ">>>>>>>>>>>>>>>>>>>>>No object /app/yolo_structure/crops/car_crop_004.jpg\n",
      "/app/yolo_structure/test/Suwon_CH01_20200721_1500_TUE_9m_NH_highway_TW5_sunny_FHD_013.png car\n",
      "/app/yolo_structure/crops/car_crop_006.jpg\n",
      "\n",
      "image 1/1 /app/yolo_structure/crops/car_crop_006.jpg: 352x416 (no detections), 18.6ms\n",
      "Speed: 0.6ms preprocess, 18.6ms inference, 4.5ms postprocess per image at shape (1, 3, 352, 416)\n",
      ">>>>>>>>>>>>>>>>>>>>>No object /app/yolo_structure/crops/car_crop_006.jpg\n",
      "/app/yolo_structure/test/Suwon_CH01_20200721_1500_TUE_9m_NH_highway_TW5_sunny_FHD_013.png car\n",
      "/app/yolo_structure/crops/car_crop_007.jpg\n",
      "\n",
      "image 1/1 /app/yolo_structure/crops/car_crop_007.jpg: 320x416 (no detections), 18.7ms\n",
      "Speed: 1.2ms preprocess, 18.7ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      ">>>>>>>>>>>>>>>>>>>>>No object /app/yolo_structure/crops/car_crop_007.jpg\n",
      "/app/yolo_structure/test/Suwon_CH01_20200721_1500_TUE_9m_NH_highway_TW5_sunny_FHD_013.png car\n",
      "/app/yolo_structure/crops/car_crop_010.jpg\n",
      "\n",
      "image 1/1 /app/yolo_structure/crops/car_crop_010.jpg: 352x416 (no detections), 18.5ms\n",
      "Speed: 1.2ms preprocess, 18.5ms inference, 4.5ms postprocess per image at shape (1, 3, 352, 416)\n",
      ">>>>>>>>>>>>>>>>>>>>>No object /app/yolo_structure/crops/car_crop_010.jpg\n",
      "/app/yolo_structure/test/Suwon_CH01_20200721_1500_TUE_9m_NH_highway_TW5_sunny_FHD_013.png car\n",
      "/app/yolo_structure/crops/car_crop_011.jpg\n",
      "\n",
      "image 1/1 /app/yolo_structure/crops/car_crop_011.jpg: 320x416 (no detections), 18.7ms\n",
      "Speed: 1.3ms preprocess, 18.7ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      ">>>>>>>>>>>>>>>>>>>>>No object /app/yolo_structure/crops/car_crop_011.jpg\n",
      "/app/yolo_structure/test/Suwon_CH01_20200721_1500_TUE_9m_NH_highway_TW5_sunny_FHD_013.png car\n",
      "/app/yolo_structure/crops/car_crop_012.jpg\n",
      "\n",
      "image 1/1 /app/yolo_structure/crops/car_crop_012.jpg: 352x416 (no detections), 5.8ms\n",
      "Speed: 1.1ms preprocess, 5.8ms inference, 0.3ms postprocess per image at shape (1, 3, 352, 416)\n",
      ">>>>>>>>>>>>>>>>>>>>>No object /app/yolo_structure/crops/car_crop_012.jpg\n",
      "/app/yolo_structure/test/Suwon_CH01_20200721_1500_TUE_9m_NH_highway_TW5_sunny_FHD_013.png car\n",
      "/app/yolo_structure/crops/car_crop_014.jpg\n",
      "\n",
      "image 1/1 /app/yolo_structure/crops/car_crop_014.jpg: 352x416 (no detections), 5.6ms\n",
      "Speed: 0.3ms preprocess, 5.6ms inference, 0.3ms postprocess per image at shape (1, 3, 352, 416)\n",
      ">>>>>>>>>>>>>>>>>>>>>No object /app/yolo_structure/crops/car_crop_014.jpg\n",
      "/app/yolo_structure/test/Suwon_CH01_20200721_1500_TUE_9m_NH_highway_TW5_sunny_FHD_013.png car\n",
      "/app/yolo_structure/crops/car_crop_018.jpg\n",
      "\n",
      "image 1/1 /app/yolo_structure/crops/car_crop_018.jpg: 416x416 (no detections), 6.5ms\n",
      "Speed: 0.4ms preprocess, 6.5ms inference, 0.3ms postprocess per image at shape (1, 3, 416, 416)\n",
      ">>>>>>>>>>>>>>>>>>>>>No object /app/yolo_structure/crops/car_crop_018.jpg\n",
      "/app/yolo_structure/test/Suwon_CH01_20200721_1500_TUE_9m_NH_highway_TW5_sunny_FHD_013.png car\n",
      "/app/yolo_structure/crops/car_crop_019.jpg\n",
      "\n",
      "image 1/1 /app/yolo_structure/crops/car_crop_019.jpg: 352x416 (no detections), 12.5ms\n",
      "Speed: 0.3ms preprocess, 12.5ms inference, 4.5ms postprocess per image at shape (1, 3, 352, 416)\n",
      ">>>>>>>>>>>>>>>>>>>>>No object /app/yolo_structure/crops/car_crop_019.jpg\n",
      "/app/yolo_structure/test/Suwon_CH01_20200721_1500_TUE_9m_NH_highway_TW5_sunny_FHD_013.png car\n",
      "/app/yolo_structure/crops/car_crop_021.jpg\n",
      "\n",
      "image 1/1 /app/yolo_structure/crops/car_crop_021.jpg: 352x416 (no detections), 11.7ms\n",
      "Speed: 1.2ms preprocess, 11.7ms inference, 4.5ms postprocess per image at shape (1, 3, 352, 416)\n",
      ">>>>>>>>>>>>>>>>>>>>>No object /app/yolo_structure/crops/car_crop_021.jpg\n",
      "/app/yolo_structure/test/hh_dash.jpg car\n",
      "/app/yolo_structure/crops/car_crop_000.jpg\n",
      "\n",
      "image 1/1 /app/yolo_structure/crops/car_crop_000.jpg: 288x416 (no detections), 19.5ms\n",
      "Speed: 1.5ms preprocess, 19.5ms inference, 4.6ms postprocess per image at shape (1, 3, 288, 416)\n",
      ">>>>>>>>>>>>>>>>>>>>>No object /app/yolo_structure/crops/car_crop_000.jpg\n",
      "/app/yolo_structure/test/hh_dash.jpg car\n",
      "/app/yolo_structure/crops/car_crop_002.jpg\n",
      "\n",
      "image 1/1 /app/yolo_structure/crops/car_crop_002.jpg: 320x416 (no detections), 18.8ms\n",
      "Speed: 0.9ms preprocess, 18.8ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      ">>>>>>>>>>>>>>>>>>>>>No object /app/yolo_structure/crops/car_crop_002.jpg\n",
      "/app/yolo_structure/test/hh_dash.jpg car\n",
      "/app/yolo_structure/crops/car_crop_003.jpg\n",
      "\n",
      "image 1/1 /app/yolo_structure/crops/car_crop_003.jpg: 96x416 (no detections), 14.9ms\n",
      "Speed: 1.2ms preprocess, 14.9ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 416)\n",
      ">>>>>>>>>>>>>>>>>>>>>No object /app/yolo_structure/crops/car_crop_003.jpg\n",
      "/app/yolo_structure/test/hh_dash.jpg car\n",
      "/app/yolo_structure/crops/car_crop_004.jpg\n",
      "\n",
      "image 1/1 /app/yolo_structure/crops/car_crop_004.jpg: 256x416 (no detections), 18.8ms\n",
      "Speed: 2.7ms preprocess, 18.8ms inference, 4.5ms postprocess per image at shape (1, 3, 256, 416)\n",
      ">>>>>>>>>>>>>>>>>>>>>No object /app/yolo_structure/crops/car_crop_004.jpg\n",
      "/app/yolo_structure/test/hh_dash.jpg car\n",
      "/app/yolo_structure/crops/car_crop_007.jpg\n",
      "\n",
      "image 1/1 /app/yolo_structure/crops/car_crop_007.jpg: 256x416 (no detections), 12.0ms\n",
      "Speed: 1.0ms preprocess, 12.0ms inference, 4.5ms postprocess per image at shape (1, 3, 256, 416)\n",
      ">>>>>>>>>>>>>>>>>>>>>No object /app/yolo_structure/crops/car_crop_007.jpg\n",
      "/app/yolo_structure/test/hh_dash.jpg car\n",
      "/app/yolo_structure/crops/car_crop_008.jpg\n",
      "\n",
      "image 1/1 /app/yolo_structure/crops/car_crop_008.jpg: 416x256 (no detections), 17.8ms\n",
      "Speed: 1.2ms preprocess, 17.8ms inference, 4.5ms postprocess per image at shape (1, 3, 416, 256)\n",
      ">>>>>>>>>>>>>>>>>>>>>No object /app/yolo_structure/crops/car_crop_008.jpg\n",
      "/app/yolo_structure/test/hh_dash.jpg car\n",
      "/app/yolo_structure/crops/car_crop_009.jpg\n",
      "\n",
      "image 1/1 /app/yolo_structure/crops/car_crop_009.jpg: 320x416 (no detections), 18.8ms\n",
      "Speed: 0.8ms preprocess, 18.8ms inference, 4.5ms postprocess per image at shape (1, 3, 320, 416)\n",
      ">>>>>>>>>>>>>>>>>>>>>No object /app/yolo_structure/crops/car_crop_009.jpg\n",
      "/app/yolo_structure/test/people_street.jpeg car\n",
      "/app/yolo_structure/crops/car_crop_005.jpg\n",
      "\n",
      "image 1/1 /app/yolo_structure/crops/car_crop_005.jpg: 384x416 (no detections), 18.4ms\n",
      "Speed: 0.8ms preprocess, 18.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 416)\n",
      ">>>>>>>>>>>>>>>>>>>>>No object /app/yolo_structure/crops/car_crop_005.jpg\n"
     ]
    }
   ],
   "source": [
    "# 현재 디렉토리와 테스트 경로 설정\n",
    "curr_dir = os.getcwd()\n",
    "test_loc = os.path.join(curr_dir, \"test\")\n",
    "crop_save_dir = os.path.join(curr_dir, \"crops\")\n",
    "\n",
    "# 모델 로드\n",
    "model = YOLO(\"yolo11x.pt\")  # 첫 번째 모델 (기본 차량 감지용)\n",
    "detailed_model = YOLO(\"my_test_model.pt\")  # 두 번째 모델 (세분화 모델)\n",
    "\n",
    "# 첫 번째 모델로 감지 수행\n",
    "results = model.predict(source=test_loc, save=True)\n",
    "\n",
    "# 감지된 결과에서 'car'만 추출\n",
    "for result in results:\n",
    "    img = result.orig_img  # 원본 이미지\n",
    "    detections = result.boxes  # 감지된 바운딩 박스들\n",
    "    \n",
    "    for i, box in enumerate(detections):\n",
    "        cls = int(box.cls)  # 클래스 ID\n",
    "        if result.names[cls] == \"car\":  # 'car' 클래스만 필터링\n",
    "            print(result.path, result.names[cls] )\n",
    "            # 바운딩 박스 좌표\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            \n",
    "            buffer_w = int((x2 - x1) * 0.1)  # 너비의 10%\n",
    "            buffer_h = int((y2 - y1) * 0.1)  # 높이의 10%\n",
    "            \n",
    "            x1 = max(0, x1 - buffer_w)\n",
    "            y1 = max(0, y1 - buffer_h)\n",
    "            x2 = min(img.shape[1], x2 + buffer_w)\n",
    "            y2 = min(img.shape[0], y2 + buffer_h)\n",
    "\n",
    "\n",
    "            # 'car' 영역을 잘라냄\n",
    "            car_crop = img[y1:y2, x1:x2]\n",
    "            crop_filename = os.path.join(crop_save_dir, f\"car_crop_{i:03}.jpg\")\n",
    "            cv2.imwrite(crop_filename, car_crop)    \n",
    "            print(crop_filename)\n",
    "            detailed_results = detailed_model.predict(source=crop_filename, conf=0.5)\n",
    "            \n",
    "            for detailed_result in detailed_results:\n",
    "                if len(detailed_result) == 0:\n",
    "                    print(f\">>>>>>>>>>>>>>>>>>>>>No object {crop_filename}\")\n",
    "                else:\n",
    "                    print(f\">>>>>>>>>>>>>>>>>>>>>Yes object {crop_filename}\")\n",
    "                    for detailed_box in detailed_result.boxes:\n",
    "                        detailed_cls = int(detailed_box.cls)\n",
    "                        detailed_label = detailed_result.names[detailed_cls]\n",
    "                        print(f\"==============Detected vehicle {crop_filename} //  {detailed_label} in\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d7bdc62c-c54e-439f-8172-b20ed7ce2dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/app/yolo_structure/crops/car_crop_005.jpg'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_filename"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
