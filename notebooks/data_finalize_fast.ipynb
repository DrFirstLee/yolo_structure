{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2638bd7-db77-4e4c-be99-ca9599e21751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3faf1cac-a832-4aaf-9cf8-a3a603078c9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>distance</th>\n",
       "      <th>event</th>\n",
       "      <th>detected</th>\n",
       "      <th>source_name</th>\n",
       "      <th>frame_hash</th>\n",
       "      <th>frame_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>20250204-170307</td>\n",
       "      <td>0</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>person</td>\n",
       "      <td>dancing.mp4</td>\n",
       "      <td>dancing_PERSON_3</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>20250204-170307</td>\n",
       "      <td>0</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>person</td>\n",
       "      <td>dancing.mp4</td>\n",
       "      <td>dancing_PERSON_4</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>20250204-170307</td>\n",
       "      <td>0</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>person</td>\n",
       "      <td>dancing.mp4</td>\n",
       "      <td>dancing_PERSON_6</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>20250204-170307</td>\n",
       "      <td>0</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>person</td>\n",
       "      <td>dancing.mp4</td>\n",
       "      <td>dancing_PERSON_7</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>20250204-170307</td>\n",
       "      <td>0</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>person</td>\n",
       "      <td>dancing.mp4</td>\n",
       "      <td>dancing_PERSON_8</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  distance   event detected  source_name  \\\n",
       "2996  20250204-170307         0  PERSON   person  dancing.mp4   \n",
       "2997  20250204-170307         0  PERSON   person  dancing.mp4   \n",
       "2998  20250204-170307         0  PERSON   person  dancing.mp4   \n",
       "2999  20250204-170307         0  PERSON   person  dancing.mp4   \n",
       "3000  20250204-170307         0  PERSON   person  dancing.mp4   \n",
       "\n",
       "            frame_hash  frame_num  \n",
       "2996  dancing_PERSON_3        443  \n",
       "2997  dancing_PERSON_4        443  \n",
       "2998  dancing_PERSON_6        443  \n",
       "2999  dancing_PERSON_7        443  \n",
       "3000  dancing_PERSON_8        443  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name =\"dancing_20250204-170238.csv\"\n",
    "df_raw =pd.read_csv(f\"/app/yolo_structure/results/{file_name}\")\n",
    "# df_raw[\"datetime\"] = pd.to_datetime(df_raw[\"datetime\"], format=\"%Y%m%d-%H%M%S.%f\")\n",
    "df_raw .tail(5)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0762f08-6fe9-487c-b084-4a443cde6987",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>distance</th>\n",
       "      <th>event</th>\n",
       "      <th>detected</th>\n",
       "      <th>source_name</th>\n",
       "      <th>frame_hash</th>\n",
       "      <th>frame_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20250204-170239</td>\n",
       "      <td>0</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>person</td>\n",
       "      <td>dancing.mp4</td>\n",
       "      <td>dancing_PERSON_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20250204-170239</td>\n",
       "      <td>0</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>person</td>\n",
       "      <td>dancing.mp4</td>\n",
       "      <td>dancing_PERSON_1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20250204-170239</td>\n",
       "      <td>0</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>person</td>\n",
       "      <td>dancing.mp4</td>\n",
       "      <td>dancing_PERSON_1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20250204-170239</td>\n",
       "      <td>0</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>person</td>\n",
       "      <td>dancing.mp4</td>\n",
       "      <td>dancing_PERSON_1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20250204-170242</td>\n",
       "      <td>0</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>person</td>\n",
       "      <td>dancing.mp4</td>\n",
       "      <td>dancing_PERSON_1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>20250204-170303</td>\n",
       "      <td>0</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>person</td>\n",
       "      <td>dancing.mp4</td>\n",
       "      <td>dancing_PERSON_9</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>20250204-170303</td>\n",
       "      <td>0</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>person</td>\n",
       "      <td>dancing.mp4</td>\n",
       "      <td>dancing_PERSON_9</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>20250204-170303</td>\n",
       "      <td>0</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>person</td>\n",
       "      <td>dancing.mp4</td>\n",
       "      <td>dancing_PERSON_9</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>20250204-170303</td>\n",
       "      <td>0</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>person</td>\n",
       "      <td>dancing.mp4</td>\n",
       "      <td>dancing_PERSON_9</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>20250204-170303</td>\n",
       "      <td>0</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>person</td>\n",
       "      <td>dancing.mp4</td>\n",
       "      <td>dancing_PERSON_9</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2497 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            datetime  distance   event detected  source_name  \\\n",
       "0    20250204-170239         0  PERSON   person  dancing.mp4   \n",
       "1    20250204-170239         0  PERSON   person  dancing.mp4   \n",
       "2    20250204-170239         0  PERSON   person  dancing.mp4   \n",
       "3    20250204-170239         0  PERSON   person  dancing.mp4   \n",
       "4    20250204-170242         0  PERSON   person  dancing.mp4   \n",
       "..               ...       ...     ...      ...          ...   \n",
       "145  20250204-170303         0  PERSON   person  dancing.mp4   \n",
       "146  20250204-170303         0  PERSON   person  dancing.mp4   \n",
       "147  20250204-170303         0  PERSON   person  dancing.mp4   \n",
       "148  20250204-170303         0  PERSON   person  dancing.mp4   \n",
       "149  20250204-170303         0  PERSON   person  dancing.mp4   \n",
       "\n",
       "           frame_hash  frame_num  \n",
       "0    dancing_PERSON_1          1  \n",
       "1    dancing_PERSON_1          2  \n",
       "2    dancing_PERSON_1          3  \n",
       "3    dancing_PERSON_1          4  \n",
       "4    dancing_PERSON_1          5  \n",
       "..                ...        ...  \n",
       "145  dancing_PERSON_9        231  \n",
       "146  dancing_PERSON_9        232  \n",
       "147  dancing_PERSON_9        233  \n",
       "148  dancing_PERSON_9        234  \n",
       "149  dancing_PERSON_9        235  \n",
       "\n",
       "[2497 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frame_hash별로 그룹핑하고, 1초 이내 5개 이상 존재하는 경우 찾기\n",
    "df_raw_person = df_raw[df_raw[\"detected\"] == \"person\"]\n",
    "df_raw_person\n",
    "\n",
    "# frame_hash별로 그룹화 후 frame_num 연속성 확인\n",
    "df_filtered_person = pd.DataFrame()\n",
    "\n",
    "grouped = df_raw_person.groupby(\"frame_hash\")\n",
    "for _, group in grouped:\n",
    "    group = group.sort_values(by=\"frame_num\").reset_index(drop=True)\n",
    "    group[\"diff\"] = group[\"frame_num\"].diff().fillna(1)\n",
    "    group[\"consec_group\"] = (group[\"diff\"] != 1).cumsum()\n",
    "    valid_groups = group.groupby(\"consec_group\").filter(lambda x: len(x) >= 5)\n",
    "    df_filtered_person = pd.concat([df_filtered_person, valid_groups.drop(columns=[\"diff\", \"consec_group\"])])\n",
    "\n",
    "# 결과 출력\n",
    "df_filtered_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735a0380-4ef1-42c2-93dc-af786c52b2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The individual depicted in the image appears to be engaged in a shopping activity, as evidenced by their presence within a grocery store and the items visible in the background.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_1.jpg / Ollama Result: THEINDIVIDUALDEPICTEDINTHEIMAGEAPPEARSTOBEENGAGEDINASHOPPINGACTIVITY,ASEVIDENCEDBYTHEIRPRESENCEWITHINAGROCERYSTOREANDTHEITEMSVISIBLEINTHEBACKGROUND\n",
      "The individual appears to be walking through a shopping center or other commercial area. Their posture and hands suggest they are either looking at something specific, perhaps an item for sale or a display, or may have stopped to read a sign, map, or advertisement. The context of their surroundings suggests they might be on a casual outing, running errands, or simply enjoying the environment.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_2.jpg / Ollama Result: THEINDIVIDUALAPPEARSTOBEWALKINGTHROUGHASHOPPINGCENTEROROTHERCOMMERCIALAREATHEIRPOSTUREANDHANDSSUGGESTTHEYAREEITHERLOOKINGATSOMETHINGSPECIFIC,PERHAPSANITEMFORSALEORADISPLAY,ORMAYHAVESTOPPEDTOREADASIGN,MAP,ORADVERTISEMENTTHECONTEXTOFTHEIRSURROUNDINGSSUGGESTSTHEYMIGHTBEONACASUALOUTING,RUNNINGERRANDS,ORSIMPLYENJOYINGTHEENVIRONMENT\n",
      "The individual in the image appears to be shopping, as evidenced by the shopping cart visible behind them. The cart contains several items, including what looks like a bottle of water and what could possibly be a jar or canister, although it's difficult to tell for sure due to the image quality. The person is likely using the cart to transport their purchases from one part of the store to another, or perhaps to the checkout counter to pay for them.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_3.jpg / Ollama Result: THEINDIVIDUALINTHEIMAGEAPPEARSTOBESHOPPING,ASEVIDENCEDBYTHESHOPPINGCARTVISIBLEBEHINDTHEMTHECARTCONTAINSSEVERALITEMS,INCLUDINGWHATLOOKSLIKEABOTTLEOFWATERANDWHATCOULDPOSSIBLYBEAJARORCANISTER,ALTHOUGHIT'SDIFFICULTTOTELLFORSUREDUETOTHEIMAGEQUALITYTHEPERSONISLIKELYUSINGTHECARTTOTRANSPORTTHEIRPURCHASESFROMONEPARTOFTHESTORETOANOTHER,ORPERHAPSTOTHECHECKOUTCOUNTERTOPAYFORTHEM\n",
      "The person in the image appears to be shopping or browsing in a store, as evidenced by the shopping cart visible behind them. They seem to be engaged in selecting items from the shelves and adding them to their cart. The person's posture and gaze suggest that they are carefully examining the products on offer, perhaps comparing prices or reading labels. Overall, the image conveys a sense of purposeful activity, as if the person is actively searching for something specific or enjoying the process of browsing through the store's offerings.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_4.jpg / Ollama Result: THEPERSONINTHEIMAGEAPPEARSTOBESHOPPINGORBROWSINGINASTORE,ASEVIDENCEDBYTHESHOPPINGCARTVISIBLEBEHINDTHEMTHEYSEEMTOBEENGAGEDINSELECTINGITEMSFROMTHESHELVESANDADDINGTHEMTOTHEIRCARTTHEPERSON'SPOSTUREANDGAZESUGGESTTHATTHEYARECAREFULLYEXAMININGTHEPRODUCTSONOFFER,PERHAPSCOMPARINGPRICESORREADINGLABELSOVERALL,THEIMAGECONVEYSASENSEOFPURPOSEFULACTIVITY,ASIFTHEPERSONISACTIVELYSEARCHINGFORSOMETHINGSPECIFICORENJOYINGTHEPROCESSOFBROWSINGTHROUGHTHESTORE'SOFFERINGS\n",
      "The woman in the image appears to be shopping at a grocery store or supermarket, as evidenced by the cart full of groceries behind her. She is likely selecting items from the shelves and placing them in the cart, which is typical behavior for someone shopping for groceries.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_5.jpg / Ollama Result: THEWOMANINTHEIMAGEAPPEARSTOBESHOPPINGATAGROCERYSTOREORSUPERMARKET,ASEVIDENCEDBYTHECARTFULLOFGROCERIESBEHINDHERSHEISLIKELYSELECTINGITEMSFROMTHESHELVESANDPLACINGTHEMINTHECART,WHICHISTYPICALBEHAVIORFORSOMEONESHOPPINGFORGROCERIES\n",
      "The woman in the image appears to be shopping or browsing in a store, as evidenced by the various items on the shelves and racks behind her. She may be examining products, reading labels, or comparing prices before making a purchase.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_6.jpg / Ollama Result: THEWOMANINTHEIMAGEAPPEARSTOBESHOPPINGORBROWSINGINASTORE,ASEVIDENCEDBYTHEVARIOUSITEMSONTHESHELVESANDRACKSBEHINDHERSHEMAYBEEXAMININGPRODUCTS,READINGLABELS,ORCOMPARINGPRICESBEFOREMAKINGAPURCHASE\n",
      "The person in the image appears to be walking through a store, possibly a grocery store or department store, based on the background and the presence of shelves and products. The person's body language suggests that they are engaged in shopping or browsing, as they are looking down at something in their hand while moving through the aisle.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_7.jpg / Ollama Result: THEPERSONINTHEIMAGEAPPEARSTOBEWALKINGTHROUGHASTORE,POSSIBLYAGROCERYSTOREORDEPARTMENTSTORE,BASEDONTHEBACKGROUNDANDTHEPRESENCEOFSHELVESANDPRODUCTSTHEPERSON'SBODYLANGUAGESUGGESTSTHATTHEYAREENGAGEDINSHOPPINGORBROWSING,ASTHEYARELOOKINGDOWNATSOMETHINGINTHEIRHANDWHILEMOVINGTHROUGHTHEAISLE\n",
      "The individual in question appears to be walking through a store, possibly carrying out some form of shopping. Their attire suggests that they are likely on their way to or from work, as evidenced by their casual yet business-like clothing.\n",
      "\n",
      "**Observations:**\n",
      "\n",
      "* The person's posture and stride suggest that they are confident and comfortable navigating the store.\n",
      "* They may be familiar with the layout and products offered, possibly having shopped there before.\n",
      "* Their attire is not overly formal, but still appears well-groomed and put-together.\n",
      "\n",
      "**Conclusion:**\n",
      "Based on their behavior and appearance, it is likely that the individual is simply running errands or doing some casual shopping.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_8.jpg / Ollama Result: THEINDIVIDUALINQUESTIONAPPEARSTOBEWALKINGTHROUGHASTORE,POSSIBLYCARRYINGOUTSOMEFORMOFSHOPPINGTHEIRATTIRESUGGESTSTHATTHEYARELIKELYONTHEIRWAYTOORFROMWORK,ASEVIDENCEDBYTHEIRCASUALYETBUSINESS-LIKECLOTHING\n",
      "\n",
      "**OBSERVATIONS:**\n",
      "\n",
      "*THEPERSON'SPOSTUREANDSTRIDESUGGESTTHATTHEYARECONFIDENTANDCOMFORTABLENAVIGATINGTHESTORE\n",
      "*THEYMAYBEFAMILIARWITHTHELAYOUTANDPRODUCTSOFFERED,POSSIBLYHAVINGSHOPPEDTHEREBEFORE\n",
      "*THEIRATTIREISNOTOVERLYFORMAL,BUTSTILLAPPEARSWELL-GROOMEDANDPUT-TOGETHER\n",
      "\n",
      "**CONCLUSION:**\n",
      "BASEDONTHEIRBEHAVIORANDAPPEARANCE,ITISLIKELYTHATTHEINDIVIDUALISSIMPLYRUNNINGERRANDSORDOINGSOMECASUALSHOPPING\n",
      "The person in the image appears to be walking through a store, possibly a grocery store or supermarket, as evidenced by the shopping cart visible behind them. They seem to be engaged in some activity, perhaps selecting items from shelves or browsing products on display, but their specific actions are not clear due to the image's limited angle and focus.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_9.jpg / Ollama Result: THEPERSONINTHEIMAGEAPPEARSTOBEWALKINGTHROUGHASTORE,POSSIBLYAGROCERYSTOREORSUPERMARKET,ASEVIDENCEDBYTHESHOPPINGCARTVISIBLEBEHINDTHEMTHEYSEEMTOBEENGAGEDINSOMEACTIVITY,PERHAPSSELECTINGITEMSFROMSHELVESORBROWSINGPRODUCTSONDISPLAY,BUTTHEIRSPECIFICACTIONSARENOTCLEARDUETOTHEIMAGE'SLIMITEDANGLEANDFOCUS\n",
      "The individual depicted in the image appears to be shopping at a grocery store, as evidenced by the shopping cart filled with various items behind them. They seem to be taking their time and carefully selecting each item, possibly comparing prices or reading labels before making a decision. The individual's posture suggests that they are engaged in a thoughtful and deliberate process, rather than simply grabbing items on impulse.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_10.jpg / Ollama Result: THEINDIVIDUALDEPICTEDINTHEIMAGEAPPEARSTOBESHOPPINGATAGROCERYSTORE,ASEVIDENCEDBYTHESHOPPINGCARTFILLEDWITHVARIOUSITEMSBEHINDTHEMTHEYSEEMTOBETAKINGTHEIRTIMEANDCAREFULLYSELECTINGEACHITEM,POSSIBLYCOMPARINGPRICESORREADINGLABELSBEFOREMAKINGADECISIONTHEINDIVIDUAL'SPOSTURESUGGESTSTHATTHEYAREENGAGEDINATHOUGHTFULANDDELIBERATEPROCESS,RATHERTHANSIMPLYGRABBINGITEMSONIMPULSE\n",
      "The individual depicted in the image appears to be engaged in a shopping activity, as evidenced by the presence of a shopping cart filled with various items. The person's attire and posture suggest that they are likely browsing through an aisle or examining products on the shelves, possibly searching for specific items or comparing prices.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_11.jpg / Ollama Result: THEINDIVIDUALDEPICTEDINTHEIMAGEAPPEARSTOBEENGAGEDINASHOPPINGACTIVITY,ASEVIDENCEDBYTHEPRESENCEOFASHOPPINGCARTFILLEDWITHVARIOUSITEMSTHEPERSON'SATTIREANDPOSTURESUGGESTTHATTHEYARELIKELYBROWSINGTHROUGHANAISLEOREXAMININGPRODUCTSONTHESHELVES,POSSIBLYSEARCHINGFORSPECIFICITEMSORCOMPARINGPRICES\n",
      "The person in the image appears to be shopping in a grocery store, as evidenced by the shopping cart full of groceries behind them. They are likely selecting items from the shelves and placing them in their cart. The person may also be browsing through the aisles, reading labels, and comparing prices before making a purchase.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_12.jpg / Ollama Result: THEPERSONINTHEIMAGEAPPEARSTOBESHOPPINGINAGROCERYSTORE,ASEVIDENCEDBYTHESHOPPINGCARTFULLOFGROCERIESBEHINDTHEMTHEYARELIKELYSELECTINGITEMSFROMTHESHELVESANDPLACINGTHEMINTHEIRCARTTHEPERSONMAYALSOBEBROWSINGTHROUGHTHEAISLES,READINGLABELS,ANDCOMPARINGPRICESBEFOREMAKINGAPURCHASE\n",
      "The woman in the image appears to be walking through a shopping centre or a similar indoor space. She seems to be either alone or accompanying someone else, as evidenced by the partially visible second figure behind her on the left side of the image. Her posture suggests that she may be engaged in conversation with this person or is simply carrying on with her daily activities without paying attention to her surroundings.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_13.jpg / Ollama Result: THEWOMANINTHEIMAGEAPPEARSTOBEWALKINGTHROUGHASHOPPINGCENTREORASIMILARINDOORSPACESHESEEMSTOBEEITHERALONEORACCOMPANYINGSOMEONEELSE,ASEVIDENCEDBYTHEPARTIALLYVISIBLESECONDFIGUREBEHINDHERONTHELEFTSIDEOFTHEIMAGEHERPOSTURESUGGESTSTHATSHEMAYBEENGAGEDINCONVERSATIONWITHTHISPERSONORISSIMPLYCARRYINGONWITHHERDAILYACTIVITIESWITHOUTPAYINGATTENTIONTOHERSURROUNDINGS\n",
      "The person in the image appears to be shopping at a grocery store, as evidenced by the cart full of groceries behind them. They are likely either checking out or restocking their cart with additional items.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_14.jpg / Ollama Result: THEPERSONINTHEIMAGEAPPEARSTOBESHOPPINGATAGROCERYSTORE,ASEVIDENCEDBYTHECARTFULLOFGROCERIESBEHINDTHEMTHEYARELIKELYEITHERCHECKINGOUTORRESTOCKINGTHEIRCARTWITHADDITIONALITEMS\n",
      "The person in this image appears to be shopping at a store based on their location within an aisle and the items around them. They are likely selecting a toy for themselves or someone else, as there appear to be toys on the shelves behind them. It's also possible that they are browsing the aisles and looking for something specific, but it seems more likely that they are shopping for a gift based on their location and the selection of toys nearby.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_15.jpg / Ollama Result: THEPERSONINTHISIMAGEAPPEARSTOBESHOPPINGATASTOREBASEDONTHEIRLOCATIONWITHINANAISLEANDTHEITEMSAROUNDTHEMTHEYARELIKELYSELECTINGATOYFORTHEMSELVESORSOMEONEELSE,ASTHEREAPPEARTOBETOYSONTHESHELVESBEHINDTHEMIT'SALSOPOSSIBLETHATTHEYAREBROWSINGTHEAISLESANDLOOKINGFORSOMETHINGSPECIFIC,BUTITSEEMSMORELIKELYTHATTHEYARESHOPPINGFORAGIFTBASEDONTHEIRLOCATIONANDTHESELECTIONOFTOYSNEARBY\n",
      "The person depicted in the image appears to be standing in a store, possibly shopping or browsing the aisles. However, it's difficult to determine their exact actions without more context.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_16.jpg / Ollama Result: THEPERSONDEPICTEDINTHEIMAGEAPPEARSTOBESTANDINGINASTORE,POSSIBLYSHOPPINGORBROWSINGTHEAISLESHOWEVER,IT'SDIFFICULTTODETERMINETHEIREXACTACTIONSWITHOUTMORECONTEXT\n",
      "The woman in the image appears to be shopping, as evidenced by her hand on a handle of what seems to be a shopping cart. However, I cannot confirm whether or not she is shopping. This may also just be an old picture from before Covid-19 and now it's only used for memes.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_17.jpg / Ollama Result: THEWOMANINTHEIMAGEAPPEARSTOBESHOPPING,ASEVIDENCEDBYHERHANDONAHANDLEOFWHATSEEMSTOBEASHOPPINGCARTHOWEVER,ICANNOTCONFIRMWHETHERORNOTSHEISSHOPPINGTHISMAYALSOJUSTBEANOLDPICTUREFROMBEFORECOVID-19ANDNOWIT'SONLYUSEDFORMEMES\n",
      "The individual in the image appears to be walking through a store, possibly a grocery store or department store. They seem to be casually strolling along the floor and looking around at various items on display, although their attention seems to be focused more on something in front of them rather than exploring the surrounding area.\n",
      "\n",
      "It's difficult to determine exactly what they are doing without more context, but based on their posture and movement, it appears that they may be browsing or shopping for something specific.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_18.jpg / Ollama Result: THEINDIVIDUALINTHEIMAGEAPPEARSTOBEWALKINGTHROUGHASTORE,POSSIBLYAGROCERYSTOREORDEPARTMENTSTORETHEYSEEMTOBECASUALLYSTROLLINGALONGTHEFLOORANDLOOKINGAROUNDATVARIOUSITEMSONDISPLAY,ALTHOUGHTHEIRATTENTIONSEEMSTOBEFOCUSEDMOREONSOMETHINGINFRONTOFTHEMRATHERTHANEXPLORINGTHESURROUNDINGAREA\n",
      "\n",
      "IT'SDIFFICULTTODETERMINEEXACTLYWHATTHEYAREDOINGWITHOUTMORECONTEXT,BUTBASEDONTHEIRPOSTUREANDMOVEMENT,ITAPPEARSTHATTHEYMAYBEBROWSINGORSHOPPINGFORSOMETHINGSPECIFIC\n",
      "The image shows a man standing in a store, facing away from the camera. He appears to be shopping or browsing through the shelves. His right hand is resting on his hip, while his left hand is not visible.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_19.jpg / Ollama Result: THEIMAGESHOWSAMANSTANDINGINASTORE,FACINGAWAYFROMTHECAMERAHEAPPEARSTOBESHOPPINGORBROWSINGTHROUGHTHESHELVESHISRIGHTHANDISRESTINGONHISHIP,WHILEHISLEFTHANDISNOTVISIBLE\n",
      "The individual depicted in the image appears to be shopping, as suggested by their stance and attire. They are likely standing in a grocery store or supermarket, possibly browsing through the aisles or examining products on shelves. The presence of a purse strap around their shoulder suggests that they have some items with them, which could indicate that they are preparing to make purchases or have already begun shopping.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_20.jpg / Ollama Result: THEINDIVIDUALDEPICTEDINTHEIMAGEAPPEARSTOBESHOPPING,ASSUGGESTEDBYTHEIRSTANCEANDATTIRETHEYARELIKELYSTANDINGINAGROCERYSTOREORSUPERMARKET,POSSIBLYBROWSINGTHROUGHTHEAISLESOREXAMININGPRODUCTSONSHELVESTHEPRESENCEOFAPURSESTRAPAROUNDTHEIRSHOULDERSUGGESTSTHATTHEYHAVESOMEITEMSWITHTHEM,WHICHCOULDINDICATETHATTHEYAREPREPARINGTOMAKEPURCHASESORHAVEALREADYBEGUNSHOPPING\n",
      "The person in this image appears to be standing still and either looking at something or waiting for someone. It's difficult to tell exactly what they are doing as there is no context, but it seems like they are not actively engaged in any activity that would require them to move around. The fact that the image was captured from behind suggests that they may be facing towards something, possibly a store shelf or a person, and are waiting for their turn to make a purchase or interact with someone.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_21.jpg / Ollama Result: THEPERSONINTHISIMAGEAPPEARSTOBESTANDINGSTILLANDEITHERLOOKINGATSOMETHINGORWAITINGFORSOMEONEIT'SDIFFICULTTOTELLEXACTLYWHATTHEYAREDOINGASTHEREISNOCONTEXT,BUTITSEEMSLIKETHEYARENOTACTIVELYENGAGEDINANYACTIVITYTHATWOULDREQUIRETHEMTOMOVEAROUNDTHEFACTTHATTHEIMAGEWASCAPTUREDFROMBEHINDSUGGESTSTHATTHEYMAYBEFACINGTOWARDSSOMETHING,POSSIBLYASTORESHELFORAPERSON,ANDAREWAITINGFORTHEIRTURNTOMAKEAPURCHASEORINTERACTWITHSOMEONE\n",
      "The person in the image appears to be shopping at a grocery store, as evidenced by the shopping cart handle visible behind them. They are likely selecting items from the shelves or scanning products with a barcode reader. The person's posture and gaze suggest that they are focused on their task, carefully selecting and adding items to their cart.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_22.jpg / Ollama Result: THEPERSONINTHEIMAGEAPPEARSTOBESHOPPINGATAGROCERYSTORE,ASEVIDENCEDBYTHESHOPPINGCARTHANDLEVISIBLEBEHINDTHEMTHEYARELIKELYSELECTINGITEMSFROMTHESHELVESORSCANNINGPRODUCTSWITHABARCODEREADERTHEPERSON'SPOSTUREANDGAZESUGGESTTHATTHEYAREFOCUSEDONTHEIRTASK,CAREFULLYSELECTINGANDADDINGITEMSTOTHEIRCART\n",
      "The individual depicted in the image appears to be shopping, as suggested by their proximity to a store and the presence of shopping carts or baskets nearby. Their stance, with their feet shoulder-width apart and hands at their sides, indicates a relaxed and confident posture, often associated with individuals who are comfortable navigating retail environments.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_23.jpg / Ollama Result: THEINDIVIDUALDEPICTEDINTHEIMAGEAPPEARSTOBESHOPPING,ASSUGGESTEDBYTHEIRPROXIMITYTOASTOREANDTHEPRESENCEOFSHOPPINGCARTSORBASKETSNEARBYTHEIRSTANCE,WITHTHEIRFEETSHOULDER-WIDTHAPARTANDHANDSATTHEIRSIDES,INDICATESARELAXEDANDCONFIDENTPOSTURE,OFTENASSOCIATEDWITHINDIVIDUALSWHOARECOMFORTABLENAVIGATINGRETAILENVIRONMENTS\n",
      "The individual appears to be shopping in a grocery store or similar retail setting, based on their proximity to the end of an aisle and the presence of shelving. Their posture suggests that they are either looking at items on the shelves or reading the labels, possibly comparing prices or considering which products to purchase.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_24.jpg / Ollama Result: THEINDIVIDUALAPPEARSTOBESHOPPINGINAGROCERYSTOREORSIMILARRETAILSETTING,BASEDONTHEIRPROXIMITYTOTHEENDOFANAISLEANDTHEPRESENCEOFSHELVINGTHEIRPOSTURESUGGESTSTHATTHEYAREEITHERLOOKINGATITEMSONTHESHELVESORREADINGTHELABELS,POSSIBLYCOMPARINGPRICESORCONSIDERINGWHICHPRODUCTSTOPURCHASE\n",
      "The person in the image appears to be shopping in a grocery store, as evidenced by the produce visible behind them and the selection of items on the shelves. They seem to be engaged in selecting products for purchase, with their hand resting on one of the items. The person's posture suggests that they are carefully examining the contents of the package, possibly reading the label or comparing prices. Overall, the image captures a moment of everyday life, where the individual is making thoughtful decisions about what to buy and how much to spend.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_25.jpg / Ollama Result: THEPERSONINTHEIMAGEAPPEARSTOBESHOPPINGINAGROCERYSTORE,ASEVIDENCEDBYTHEPRODUCEVISIBLEBEHINDTHEMANDTHESELECTIONOFITEMSONTHESHELVESTHEYSEEMTOBEENGAGEDINSELECTINGPRODUCTSFORPURCHASE,WITHTHEIRHANDRESTINGONONEOFTHEITEMSTHEPERSON'SPOSTURESUGGESTSTHATTHEYARECAREFULLYEXAMININGTHECONTENTSOFTHEPACKAGE,POSSIBLYREADINGTHELABELORCOMPARINGPRICESOVERALL,THEIMAGECAPTURESAMOMENTOFEVERYDAYLIFE,WHERETHEINDIVIDUALISMAKINGTHOUGHTFULDECISIONSABOUTWHATTOBUYANDHOWMUCHTOSPEND\n",
      "The person in the image appears to be shopping or browsing in a store, as evidenced by the selection of products on shelves behind them and the neutral expression on their face. They seem to be taking their time, looking at various items without any apparent urgency or distress.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_26.jpg / Ollama Result: THEPERSONINTHEIMAGEAPPEARSTOBESHOPPINGORBROWSINGINASTORE,ASEVIDENCEDBYTHESELECTIONOFPRODUCTSONSHELVESBEHINDTHEMANDTHENEUTRALEXPRESSIONONTHEIRFACETHEYSEEMTOBETAKINGTHEIRTIME,LOOKINGATVARIOUSITEMSWITHOUTANYAPPARENTURGENCYORDISTRESS\n",
      "The woman in the image appears to be shopping or browsing in a retail setting, possibly a grocery store or department store. She is standing with her back to the camera and facing towards the right side of the image, suggesting that she may be looking at products on a shelf or in a display case.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_27.jpg / Ollama Result: THEWOMANINTHEIMAGEAPPEARSTOBESHOPPINGORBROWSINGINARETAILSETTING,POSSIBLYAGROCERYSTOREORDEPARTMENTSTORESHEISSTANDINGWITHHERBACKTOTHECAMERAANDFACINGTOWARDSTHERIGHTSIDEOFTHEIMAGE,SUGGESTINGTHATSHEMAYBELOOKINGATPRODUCTSONASHELFORINADISPLAYCASE\n",
      "The individual depicted in the image appears to be navigating through a grocery store, likely engaged in shopping activities. The person's posture and movement suggest they are carefully examining products on shelves or scanning labels, possibly selecting items for purchase. Their attention seems focused on the task at hand, with no visible signs of interaction with others or engagement in non-shopping behaviors.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_28.jpg / Ollama Result: THEINDIVIDUALDEPICTEDINTHEIMAGEAPPEARSTOBENAVIGATINGTHROUGHAGROCERYSTORE,LIKELYENGAGEDINSHOPPINGACTIVITIESTHEPERSON'SPOSTUREANDMOVEMENTSUGGESTTHEYARECAREFULLYEXAMININGPRODUCTSONSHELVESORSCANNINGLABELS,POSSIBLYSELECTINGITEMSFORPURCHASETHEIRATTENTIONSEEMSFOCUSEDONTHETASKATHAND,WITHNOVISIBLESIGNSOFINTERACTIONWITHOTHERSORENGAGEMENTINNON-SHOPPINGBEHAVIORS\n",
      "The person in the image appears to be shopping, as they are standing in a store and looking at shelves. They may also be waiting for someone or something, as they are standing still and not actively engaged in any activity. It's also possible that they are taking a break or resting while out and about.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_29.jpg / Ollama Result: THEPERSONINTHEIMAGEAPPEARSTOBESHOPPING,ASTHEYARESTANDINGINASTOREANDLOOKINGATSHELVESTHEYMAYALSOBEWAITINGFORSOMEONEORSOMETHING,ASTHEYARESTANDINGSTILLANDNOTACTIVELYENGAGEDINANYACTIVITYIT'SALSOPOSSIBLETHATTHEYARETAKINGABREAKORRESTINGWHILEOUTANDABOUT\n",
      "The elderly lady appears to be shopping in a grocery store, as evidenced by her presence in an aisle with shelves stocked with various products. Her handbag strap indicates that she has a bag nearby, likely containing items she wishes to purchase or has already purchased. The overall atmosphere suggests a routine shopping trip, possibly for daily essentials.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_30.jpg / Ollama Result: THEELDERLYLADYAPPEARSTOBESHOPPINGINAGROCERYSTORE,ASEVIDENCEDBYHERPRESENCEINANAISLEWITHSHELVESSTOCKEDWITHVARIOUSPRODUCTSHERHANDBAGSTRAPINDICATESTHATSHEHASABAGNEARBY,LIKELYCONTAININGITEMSSHEWISHESTOPURCHASEORHASALREADYPURCHASEDTHEOVERALLATMOSPHERESUGGESTSAROUTINESHOPPINGTRIP,POSSIBLYFORDAILYESSENTIALS\n",
      "The person in the image appears to be shopping in a grocery store, as evidenced by the cart full of groceries in the background and the fact that they are holding a shopping basket. They seem to be carefully selecting items from the shelves, possibly comparing prices or reading labels. The person's posture suggests a thoughtful and deliberate approach to their shopping, indicating that they are taking their time to make informed decisions about their purchases.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_31.jpg / Ollama Result: THEPERSONINTHEIMAGEAPPEARSTOBESHOPPINGINAGROCERYSTORE,ASEVIDENCEDBYTHECARTFULLOFGROCERIESINTHEBACKGROUNDANDTHEFACTTHATTHEYAREHOLDINGASHOPPINGBASKETTHEYSEEMTOBECAREFULLYSELECTINGITEMSFROMTHESHELVES,POSSIBLYCOMPARINGPRICESORREADINGLABELSTHEPERSON'SPOSTURESUGGESTSATHOUGHTFULANDDELIBERATEAPPROACHTOTHEIRSHOPPING,INDICATINGTHATTHEYARETAKINGTHEIRTIMETOMAKEINFORMEDDECISIONSABOUTTHEIRPURCHASES\n",
      "Based on the image, it appears that the person is dancing in a store. Their feet are lifted off the ground, and their arms are extended out to the sides. The person's body language suggests that they are enjoying themselves and having fun. It’s possible that they may be listening to music or watching something on their phone.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_32.jpg / Ollama Result: BASEDONTHEIMAGE,ITAPPEARSTHATTHEPERSONISDANCINGINASTORETHEIRFEETARELIFTEDOFFTHEGROUND,ANDTHEIRARMSAREEXTENDEDOUTTOTHESIDESTHEPERSON'SBODYLANGUAGESUGGESTSTHATTHEYAREENJOYINGTHEMSELVESANDHAVINGFUNIT’SPOSSIBLETHATTHEYMAYBELISTENINGTOMUSICORWATCHINGSOMETHINGONTHEIRPHONE\n",
      "The person depicted in the image appears to be walking through a store, likely shopping for groceries or other essentials. Their posture suggests they are focused on their surroundings and may be reading labels or checking prices on products. The person's pace seems relaxed, indicating that they are taking their time to browse the aisles and make informed purchasing decisions.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_33.jpg / Ollama Result: THEPERSONDEPICTEDINTHEIMAGEAPPEARSTOBEWALKINGTHROUGHASTORE,LIKELYSHOPPINGFORGROCERIESOROTHERESSENTIALSTHEIRPOSTURESUGGESTSTHEYAREFOCUSEDONTHEIRSURROUNDINGSANDMAYBEREADINGLABELSORCHECKINGPRICESONPRODUCTSTHEPERSON'SPACESEEMSRELAXED,INDICATINGTHATTHEYARETAKINGTHEIRTIMETOBROWSETHEAISLESANDMAKEINFORMEDPURCHASINGDECISIONS\n",
      "The individual depicted in the image appears to be engaged in shopping, as evidenced by their presence within a retail environment. They are likely selecting items from shelves or browsing through various sections of the store.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_34.jpg / Ollama Result: THEINDIVIDUALDEPICTEDINTHEIMAGEAPPEARSTOBEENGAGEDINSHOPPING,ASEVIDENCEDBYTHEIRPRESENCEWITHINARETAILENVIRONMENTTHEYARELIKELYSELECTINGITEMSFROMSHELVESORBROWSINGTHROUGHVARIOUSSECTIONSOFTHESTORE\n",
      "The individual depicted in the image appears to be walking through a grocery store, as evidenced by the shopping cart and shelves of food products visible in the background.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_35.jpg / Ollama Result: THEINDIVIDUALDEPICTEDINTHEIMAGEAPPEARSTOBEWALKINGTHROUGHAGROCERYSTORE,ASEVIDENCEDBYTHESHOPPINGCARTANDSHELVESOFFOODPRODUCTSVISIBLEINTHEBACKGROUND\n",
      "The individual depicted in the image appears to be engaged in shopping, as evidenced by the presence of a grocery cart handle visible near their right elbow and the various products on display behind them. The overall atmosphere suggests that they are actively selecting items for purchase, likely while navigating through an aisle within a retail establishment.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_36.jpg / Ollama Result: THEINDIVIDUALDEPICTEDINTHEIMAGEAPPEARSTOBEENGAGEDINSHOPPING,ASEVIDENCEDBYTHEPRESENCEOFAGROCERYCARTHANDLEVISIBLENEARTHEIRRIGHTELBOWANDTHEVARIOUSPRODUCTSONDISPLAYBEHINDTHEMTHEOVERALLATMOSPHERESUGGESTSTHATTHEYAREACTIVELYSELECTINGITEMSFORPURCHASE,LIKELYWHILENAVIGATINGTHROUGHANAISLEWITHINARETAILESTABLISHMENT\n",
      "The person in the image appears to be shopping at a grocery store, as evidenced by the shopping cart handle visible behind them. They are likely selecting items from the shelves and placing them in their cart. The person's posture suggests they are engaged in the activity of shopping, with their body facing towards the shelves and their hand reaching out to select an item.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_37.jpg / Ollama Result: THEPERSONINTHEIMAGEAPPEARSTOBESHOPPINGATAGROCERYSTORE,ASEVIDENCEDBYTHESHOPPINGCARTHANDLEVISIBLEBEHINDTHEMTHEYARELIKELYSELECTINGITEMSFROMTHESHELVESANDPLACINGTHEMINTHEIRCARTTHEPERSON'SPOSTURESUGGESTSTHEYAREENGAGEDINTHEACTIVITYOFSHOPPING,WITHTHEIRBODYFACINGTOWARDSTHESHELVESANDTHEIRHANDREACHINGOUTTOSELECTANITEM\n",
      "The individual depicted in the image appears to be walking through a shopping area, possibly a grocery store or supermarket. The person's attire and the surrounding environment suggest that they are engaged in some form of retail activity, such as browsing shelves or selecting items from a display.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_38.jpg / Ollama Result: THEINDIVIDUALDEPICTEDINTHEIMAGEAPPEARSTOBEWALKINGTHROUGHASHOPPINGAREA,POSSIBLYAGROCERYSTOREORSUPERMARKETTHEPERSON'SATTIREANDTHESURROUNDINGENVIRONMENTSUGGESTTHATTHEYAREENGAGEDINSOMEFORMOFRETAILACTIVITY,SUCHASBROWSINGSHELVESORSELECTINGITEMSFROMADISPLAY\n",
      "The person in the image appears to be shopping at a grocery store, as evidenced by the produce visible behind them and the fact that they are pushing an empty cart. They appear to be either walking or standing still, possibly reading the labels on items on the shelves.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_39.jpg / Ollama Result: THEPERSONINTHEIMAGEAPPEARSTOBESHOPPINGATAGROCERYSTORE,ASEVIDENCEDBYTHEPRODUCEVISIBLEBEHINDTHEMANDTHEFACTTHATTHEYAREPUSHINGANEMPTYCARTTHEYAPPEARTOBEEITHERWALKINGORSTANDINGSTILL,POSSIBLYREADINGTHELABELSONITEMSONTHESHELVES\n",
      "The person in the image appears to be shopping in a grocery store, as evidenced by the shopping cart filled with various items behind them. They are likely selecting products from the shelves or scanning items at a self-checkout, going about their daily errands and stocking up on essentials.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_40.jpg / Ollama Result: THEPERSONINTHEIMAGEAPPEARSTOBESHOPPINGINAGROCERYSTORE,ASEVIDENCEDBYTHESHOPPINGCARTFILLEDWITHVARIOUSITEMSBEHINDTHEMTHEYARELIKELYSELECTINGPRODUCTSFROMTHESHELVESORSCANNINGITEMSATASELF-CHECKOUT,GOINGABOUTTHEIRDAILYERRANDSANDSTOCKINGUPONESSENTIALS\n",
      "The image shows an older woman standing in a grocery store, possibly shopping or browsing. Based on her posture and gaze, it appears that she may be looking at something in particular, perhaps reading the labels on some products or examining a certain item more closely.\n",
      "\n",
      "It's worth noting that the image is quite pixelated, which makes it difficult to discern further details about her actions or surroundings. However, based on the context of the image and the woman's posture, it seems likely that she is engaged in some form of shopping or browsing behavior.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_41.jpg / Ollama Result: THEIMAGESHOWSANOLDERWOMANSTANDINGINAGROCERYSTORE,POSSIBLYSHOPPINGORBROWSINGBASEDONHERPOSTUREANDGAZE,ITAPPEARSTHATSHEMAYBELOOKINGATSOMETHINGINPARTICULAR,PERHAPSREADINGTHELABELSONSOMEPRODUCTSOREXAMININGACERTAINITEMMORECLOSELY\n",
      "\n",
      "IT'SWORTHNOTINGTHATTHEIMAGEISQUITEPIXELATED,WHICHMAKESITDIFFICULTTODISCERNFURTHERDETAILSABOUTHERACTIONSORSURROUNDINGSHOWEVER,BASEDONTHECONTEXTOFTHEIMAGEANDTHEWOMAN'SPOSTURE,ITSEEMSLIKELYTHATSHEISENGAGEDINSOMEFORMOFSHOPPINGORBROWSINGBEHAVIOR\n",
      "The individual depicted in the image appears to be shopping at a grocery store, as evidenced by the presence of shopping carts and shelves stocked with various products. The person seems to be engaged in the act of selecting items from the shelves and placing them into their cart. This behavior is consistent with that of someone who is actively shopping for groceries.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_42.jpg / Ollama Result: THEINDIVIDUALDEPICTEDINTHEIMAGEAPPEARSTOBESHOPPINGATAGROCERYSTORE,ASEVIDENCEDBYTHEPRESENCEOFSHOPPINGCARTSANDSHELVESSTOCKEDWITHVARIOUSPRODUCTSTHEPERSONSEEMSTOBEENGAGEDINTHEACTOFSELECTINGITEMSFROMTHESHELVESANDPLACINGTHEMINTOTHEIRCARTTHISBEHAVIORISCONSISTENTWITHTHATOFSOMEONEWHOISACTIVELYSHOPPINGFORGROCERIES\n",
      "The image shows a woman standing in a store, possibly shopping. Here are some observations based on the image:\n",
      "\n",
      "* The woman appears to be middle-aged or older.\n",
      "* She has short gray hair and is wearing a beige t-shirt, white capri pants, and white sneakers.\n",
      "* Her left hand is holding a black purse with a long strap.\n",
      "* The background of the image shows a store with shelves and products, but it's not clear what type of store this is.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_43.jpg / Ollama Result: THEIMAGESHOWSAWOMANSTANDINGINASTORE,POSSIBLYSHOPPINGHEREARESOMEOBSERVATIONSBASEDONTHEIMAGE:\n",
      "\n",
      "*THEWOMANAPPEARSTOBEMIDDLE-AGEDOROLDER\n",
      "*SHEHASSHORTGRAYHAIRANDISWEARINGABEIGET-SHIRT,WHITECAPRIPANTS,ANDWHITESNEAKERS\n",
      "*HERLEFTHANDISHOLDINGABLACKPURSEWITHALONGSTRAP\n",
      "*THEBACKGROUNDOFTHEIMAGESHOWSASTOREWITHSHELVESANDPRODUCTS,BUTIT'SNOTCLEARWHATTYPEOFSTORETHISIS\n",
      "The individual depicted in the image appears to be engaged in shopping, as evidenced by the presence of a shopping cart filled with various items. The person's posture and facial expression suggest that they are carefully selecting products, possibly taking their time to compare prices or read labels. Overall, the scene suggests a leisurely and thoughtful approach to shopping, rather than a rushed or hurried one.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_44.jpg / Ollama Result: THEINDIVIDUALDEPICTEDINTHEIMAGEAPPEARSTOBEENGAGEDINSHOPPING,ASEVIDENCEDBYTHEPRESENCEOFASHOPPINGCARTFILLEDWITHVARIOUSITEMSTHEPERSON'SPOSTUREANDFACIALEXPRESSIONSUGGESTTHATTHEYARECAREFULLYSELECTINGPRODUCTS,POSSIBLYTAKINGTHEIRTIMETOCOMPAREPRICESORREADLABELSOVERALL,THESCENESUGGESTSALEISURELYANDTHOUGHTFULAPPROACHTOSHOPPING,RATHERTHANARUSHEDORHURRIEDONE\n",
      "The image depicts an older woman, likely a senior citizen, standing in what appears to be a grocery store or supermarket setting. She is dressed in casual attire, consisting of white pants and a beige t-shirt paired with white sneakers. Her gray hair is styled in loose waves, framing her face.\n",
      "\n",
      "The woman's posture suggests that she is either waiting for someone or something, or perhaps lost in thought while shopping. The blurred image makes it difficult to discern any specific actions or activities she may be engaged in. However, the context of the setting implies that she is likely browsing through the aisles, selecting items from shelves, and placing them into her cart.\n",
      "\n",
      "The woman's facial expression is not visible due to the blurriness of the image. Nevertheless, her relaxed demeanor and lack of urgency suggest that she is taking her time while shopping, possibly enjoying the experience or savoring the moment. The overall atmosphere of the scene appears calm and peaceful, with no signs of distress or anxiety.\n",
      "\n",
      "In summary, the woman in the image appears to be engaged in a leisurely shopping activity, perhaps taking advantage of the opportunity to browse through the store's offerings at her own pace. Her relaxed demeanor and lack of urgency suggest that she is enjoying the experience, and the overall atmosphere of the scene conveys a sense of serenity and calmness.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_45.jpg / Ollama Result: THEIMAGEDEPICTSANOLDERWOMAN,LIKELYASENIORCITIZEN,STANDINGINWHATAPPEARSTOBEAGROCERYSTOREORSUPERMARKETSETTINGSHEISDRESSEDINCASUALATTIRE,CONSISTINGOFWHITEPANTSANDABEIGET-SHIRTPAIREDWITHWHITESNEAKERSHERGRAYHAIRISSTYLEDINLOOSEWAVES,FRAMINGHERFACE\n",
      "\n",
      "THEWOMAN'SPOSTURESUGGESTSTHATSHEISEITHERWAITINGFORSOMEONEORSOMETHING,ORPERHAPSLOSTINTHOUGHTWHILESHOPPINGTHEBLURREDIMAGEMAKESITDIFFICULTTODISCERNANYSPECIFICACTIONSORACTIVITIESSHEMAYBEENGAGEDINHOWEVER,THECONTEXTOFTHESETTINGIMPLIESTHATSHEISLIKELYBROWSINGTHROUGHTHEAISLES,SELECTINGITEMSFROMSHELVES,ANDPLACINGTHEMINTOHERCART\n",
      "\n",
      "THEWOMAN'SFACIALEXPRESSIONISNOTVISIBLEDUETOTHEBLURRINESSOFTHEIMAGENEVERTHELESS,HERRELAXEDDEMEANORANDLACKOFURGENCYSUGGESTTHATSHEISTAKINGHERTIMEWHILESHOPPING,POSSIBLYENJOYINGTHEEXPERIENCEORSAVORINGTHEMOMENTTHEOVERALLATMOSPHEREOFTHESCENEAPPEARSCALMANDPEACEFUL,WITHNOSIGNSOFDISTRESSORANXIETY\n",
      "\n",
      "INSUMMARY,THEWOMANINTHEIMAGEAPPEARSTOBEENGAGEDINALEISURELYSHOPPINGACTIVITY,PERHAPSTAKINGADVANTAGEOFTHEOPPORTUNITYTOBROWSETHROUGHTHESTORE'SOFFERINGSATHEROWNPACEHERRELAXEDDEMEANORANDLACKOFURGENCYSUGGESTTHATSHEISENJOYINGTHEEXPERIENCE,ANDTHEOVERALLATMOSPHEREOFTHESCENECONVEYSASENSEOFSERENITYANDCALMNESS\n",
      "The individual in the image appears to be navigating through a store, possibly a grocery store or supermarket. The person's posture and movement suggest that they are actively shopping, with their hands by their sides as if they are holding items or preparing to pick up more. Their gaze seems focused on the shelves or products ahead, indicating that they are engaged in selecting goods for purchase.\n",
      "\n",
      "The context of the image implies a casual, everyday activity, such as running errands or doing grocery shopping, rather than a formal event or performance.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_46.jpg / Ollama Result: THEINDIVIDUALINTHEIMAGEAPPEARSTOBENAVIGATINGTHROUGHASTORE,POSSIBLYAGROCERYSTOREORSUPERMARKETTHEPERSON'SPOSTUREANDMOVEMENTSUGGESTTHATTHEYAREACTIVELYSHOPPING,WITHTHEIRHANDSBYTHEIRSIDESASIFTHEYAREHOLDINGITEMSORPREPARINGTOPICKUPMORETHEIRGAZESEEMSFOCUSEDONTHESHELVESORPRODUCTSAHEAD,INDICATINGTHATTHEYAREENGAGEDINSELECTINGGOODSFORPURCHASE\n",
      "\n",
      "THECONTEXTOFTHEIMAGEIMPLIESACASUAL,EVERYDAYACTIVITY,SUCHASRUNNINGERRANDSORDOINGGROCERYSHOPPING,RATHERTHANAFORMALEVENTORPERFORMANCE\n",
      "The individual depicted in the image appears to be walking through a store, possibly engaged in shopping or browsing. Their posture and movement suggest they are navigating the aisles or examining products on shelves. The context of the image, including the presence of other shoppers and the store's layout, supports this interpretation.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_47.jpg / Ollama Result: THEINDIVIDUALDEPICTEDINTHEIMAGEAPPEARSTOBEWALKINGTHROUGHASTORE,POSSIBLYENGAGEDINSHOPPINGORBROWSINGTHEIRPOSTUREANDMOVEMENTSUGGESTTHEYARENAVIGATINGTHEAISLESOREXAMININGPRODUCTSONSHELVESTHECONTEXTOFTHEIMAGE,INCLUDINGTHEPRESENCEOFOTHERSHOPPERSANDTHESTORE'SLAYOUT,SUPPORTSTHISINTERPRETATION\n",
      "The image shows an elderly woman in a supermarket setting, seemingly unaware of her surroundings and potentially experiencing some kind of cognitive impairment or disorientation.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_48.jpg / Ollama Result: THEIMAGESHOWSANELDERLYWOMANINASUPERMARKETSETTING,SEEMINGLYUNAWAREOFHERSURROUNDINGSANDPOTENTIALLYEXPERIENCINGSOMEKINDOFCOGNITIVEIMPAIRMENTORDISORIENTATION\n",
      "The individual depicted in the image appears to be engaged in shopping, as evidenced by the presence of a shopping cart filled with various items. The person's posture and facial expression suggest that they are intently focused on selecting products, possibly taking their time to compare prices or read labels. Overall, the scene suggests a casual and deliberate approach to grocery shopping.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_49.jpg / Ollama Result: THEINDIVIDUALDEPICTEDINTHEIMAGEAPPEARSTOBEENGAGEDINSHOPPING,ASEVIDENCEDBYTHEPRESENCEOFASHOPPINGCARTFILLEDWITHVARIOUSITEMSTHEPERSON'SPOSTUREANDFACIALEXPRESSIONSUGGESTTHATTHEYAREINTENTLYFOCUSEDONSELECTINGPRODUCTS,POSSIBLYTAKINGTHEIRTIMETOCOMPAREPRICESORREADLABELSOVERALL,THESCENESUGGESTSACASUALANDDELIBERATEAPPROACHTOGROCERYSHOPPING\n",
      "Based on the image, it appears that the person is standing in a store, possibly shopping or browsing. The person is wearing casual clothing and has their back to the camera, with their right leg slightly bent at the knee. Their left arm is hanging down by their side, while their right arm is holding onto something, possibly a shopping bag or cart.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_50.jpg / Ollama Result: BASEDONTHEIMAGE,ITAPPEARSTHATTHEPERSONISSTANDINGINASTORE,POSSIBLYSHOPPINGORBROWSINGTHEPERSONISWEARINGCASUALCLOTHINGANDHASTHEIRBACKTOTHECAMERA,WITHTHEIRRIGHTLEGSLIGHTLYBENTATTHEKNEETHEIRLEFTARMISHANGINGDOWNBYTHEIRSIDE,WHILETHEIRRIGHTARMISHOLDINGONTOSOMETHING,POSSIBLYASHOPPINGBAGORCART\n",
      "The person in the image appears to be shopping in a grocery store, as evidenced by the shopping cart filled with various items behind them. They are likely selecting products from the shelves and placing them in their cart, which is a common activity for customers in a grocery store.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_51.jpg / Ollama Result: THEPERSONINTHEIMAGEAPPEARSTOBESHOPPINGINAGROCERYSTORE,ASEVIDENCEDBYTHESHOPPINGCARTFILLEDWITHVARIOUSITEMSBEHINDTHEMTHEYARELIKELYSELECTINGPRODUCTSFROMTHESHELVESANDPLACINGTHEMINTHEIRCART,WHICHISACOMMONACTIVITYFORCUSTOMERSINAGROCERYSTORE\n",
      "The woman in the image appears to be shopping in a grocery store, as evidenced by the various products visible on shelves in the background. She seems focused on selecting items from the shelf in front of her. The woman's posture and gaze suggest that she is carefully examining the products before making a decision about which ones to purchase.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_55.jpg / Ollama Result: THEWOMANINTHEIMAGEAPPEARSTOBESHOPPINGINAGROCERYSTORE,ASEVIDENCEDBYTHEVARIOUSPRODUCTSVISIBLEONSHELVESINTHEBACKGROUNDSHESEEMSFOCUSEDONSELECTINGITEMSFROMTHESHELFINFRONTOFHERTHEWOMAN'SPOSTUREANDGAZESUGGESTTHATSHEISCAREFULLYEXAMININGTHEPRODUCTSBEFOREMAKINGADECISIONABOUTWHICHONESTOPURCHASE\n",
      "The person in the image appears to be shopping, perhaps at a grocery store or similar retail establishment. They are wearing casual clothing and have a small bag slung over their shoulder, which suggests that they may be running errands or doing some light shopping. The background of the image is not clear enough to determine exactly where the person is, but based on the context clues it is likely that they are in a store of some kind.\n",
      "\n",
      "It's worth noting that the person's facial expression and body language suggest that they may be feeling relaxed and comfortable, possibly enjoying their shopping experience. However, without more information or context it is impossible to say for certain what the person is doing or how they are feeling.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_56.jpg / Ollama Result: THEPERSONINTHEIMAGEAPPEARSTOBESHOPPING,PERHAPSATAGROCERYSTOREORSIMILARRETAILESTABLISHMENTTHEYAREWEARINGCASUALCLOTHINGANDHAVEASMALLBAGSLUNGOVERTHEIRSHOULDER,WHICHSUGGESTSTHATTHEYMAYBERUNNINGERRANDSORDOINGSOMELIGHTSHOPPINGTHEBACKGROUNDOFTHEIMAGEISNOTCLEARENOUGHTODETERMINEEXACTLYWHERETHEPERSONIS,BUTBASEDONTHECONTEXTCLUESITISLIKELYTHATTHEYAREINASTOREOFSOMEKIND\n",
      "\n",
      "IT'SWORTHNOTINGTHATTHEPERSON'SFACIALEXPRESSIONANDBODYLANGUAGESUGGESTTHATTHEYMAYBEFEELINGRELAXEDANDCOMFORTABLE,POSSIBLYENJOYINGTHEIRSHOPPINGEXPERIENCEHOWEVER,WITHOUTMOREINFORMATIONORCONTEXTITISIMPOSSIBLETOSAYFORCERTAINWHATTHEPERSONISDOINGORHOWTHEYAREFEELING\n",
      "The individual depicted in the image appears to be shopping, likely in a grocery store setting. They are holding a black bag or container that could potentially contain items they have already purchased or plan to purchase while shopping.\n",
      "\n",
      "Based on the context of the image and their actions, it seems as though this person is engaged in a routine activity such as grocery shopping or running errands.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_57.jpg / Ollama Result: THEINDIVIDUALDEPICTEDINTHEIMAGEAPPEARSTOBESHOPPING,LIKELYINAGROCERYSTORESETTINGTHEYAREHOLDINGABLACKBAGORCONTAINERTHATCOULDPOTENTIALLYCONTAINITEMSTHEYHAVEALREADYPURCHASEDORPLANTOPURCHASEWHILESHOPPING\n",
      "\n",
      "BASEDONTHECONTEXTOFTHEIMAGEANDTHEIRACTIONS,ITSEEMSASTHOUGHTHISPERSONISENGAGEDINAROUTINEACTIVITYSUCHASGROCERYSHOPPINGORRUNNINGERRANDS\n",
      "The individual depicted in the image appears to be navigating within a retail establishment, likely engaged in the act of shopping. The context suggests that they are either browsing or selecting items from shelves or displays, with their hands extended and arms outstretched in a manner consistent with the act of reaching for or retrieving merchandise.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_58.jpg / Ollama Result: THEINDIVIDUALDEPICTEDINTHEIMAGEAPPEARSTOBENAVIGATINGWITHINARETAILESTABLISHMENT,LIKELYENGAGEDINTHEACTOFSHOPPINGTHECONTEXTSUGGESTSTHATTHEYAREEITHERBROWSINGORSELECTINGITEMSFROMSHELVESORDISPLAYS,WITHTHEIRHANDSEXTENDEDANDARMSOUTSTRETCHEDINAMANNERCONSISTENTWITHTHEACTOFREACHINGFORORRETRIEVINGMERCHANDISE\n",
      "The person in this image appears to be shopping at a grocery store, as suggested by the aisle of groceries behind them. They appear to either be reaching for an item on a shelf or walking away from one. The person has their back turned towards the camera and seems to be focused on whatever they are doing.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_59.jpg / Ollama Result: THEPERSONINTHISIMAGEAPPEARSTOBESHOPPINGATAGROCERYSTORE,ASSUGGESTEDBYTHEAISLEOFGROCERIESBEHINDTHEMTHEYAPPEARTOEITHERBEREACHINGFORANITEMONASHELFORWALKINGAWAYFROMONETHEPERSONHASTHEIRBACKTURNEDTOWARDSTHECAMERAANDSEEMSTOBEFOCUSEDONWHATEVERTHEYAREDOING\n",
      "The person in the image appears to be dancing or posing for someone off camera. Their arms are outstretched, and their legs are bent as if they are about to jump up and down. The person's body language suggests that they are trying to draw attention to themselves, perhaps to entertain others or to show off their dance moves.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_60.jpg / Ollama Result: THEPERSONINTHEIMAGEAPPEARSTOBEDANCINGORPOSINGFORSOMEONEOFFCAMERATHEIRARMSAREOUTSTRETCHED,ANDTHEIRLEGSAREBENTASIFTHEYAREABOUTTOJUMPUPANDDOWNTHEPERSON'SBODYLANGUAGESUGGESTSTHATTHEYARETRYINGTODRAWATTENTIONTOTHEMSELVES,PERHAPSTOENTERTAINOTHERSORTOSHOWOFFTHEIRDANCEMOVES\n",
      "The person in the image appears to be shopping at a grocery store, as evidenced by the selection of groceries on the shelves behind them. They are likely either looking for a specific item or browsing the aisles to find something that catches their eye. The person may also be interacting with other shoppers or employees in the store, such as asking for help finding an item or engaging in conversation while waiting in line.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_61.jpg / Ollama Result: THEPERSONINTHEIMAGEAPPEARSTOBESHOPPINGATAGROCERYSTORE,ASEVIDENCEDBYTHESELECTIONOFGROCERIESONTHESHELVESBEHINDTHEMTHEYARELIKELYEITHERLOOKINGFORASPECIFICITEMORBROWSINGTHEAISLESTOFINDSOMETHINGTHATCATCHESTHEIREYETHEPERSONMAYALSOBEINTERACTINGWITHOTHERSHOPPERSOREMPLOYEESINTHESTORE,SUCHASASKINGFORHELPFINDINGANITEMORENGAGINGINCONVERSATIONWHILEWAITINGINLINE\n",
      "The individual depicted in the image appears to be dancing or performing some type of expressive movement, as evidenced by their bent legs and arms. The context suggests they may be performing for an audience or entertaining others in a public setting.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_62.jpg / Ollama Result: THEINDIVIDUALDEPICTEDINTHEIMAGEAPPEARSTOBEDANCINGORPERFORMINGSOMETYPEOFEXPRESSIVEMOVEMENT,ASEVIDENCEDBYTHEIRBENTLEGSANDARMSTHECONTEXTSUGGESTSTHEYMAYBEPERFORMINGFORANAUDIENCEORENTERTAININGOTHERSINAPUBLICSETTING\n",
      "The individual appears to be in a store, possibly a grocery store or department store. The person is standing with their feet spread apart and arms outstretched, which could indicate they are attempting to balance on one foot or trying to demonstrate an activity. They may also be reaching for something in the background or making a gesture towards someone else.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_63.jpg / Ollama Result: THEINDIVIDUALAPPEARSTOBEINASTORE,POSSIBLYAGROCERYSTOREORDEPARTMENTSTORETHEPERSONISSTANDINGWITHTHEIRFEETSPREADAPARTANDARMSOUTSTRETCHED,WHICHCOULDINDICATETHEYAREATTEMPTINGTOBALANCEONONEFOOTORTRYINGTODEMONSTRATEANACTIVITYTHEYMAYALSOBEREACHINGFORSOMETHINGINTHEBACKGROUNDORMAKINGAGESTURETOWARDSSOMEONEELSE\n",
      "The individual in the image appears to be walking with a shopping cart through a store, possibly grocery shopping. The presence of other shoppers and the aisle layout suggest that this is an indoor setting. The person seems to be engaged in the shopping process, carefully selecting items and placing them in the cart.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_64.jpg / Ollama Result: THEINDIVIDUALINTHEIMAGEAPPEARSTOBEWALKINGWITHASHOPPINGCARTTHROUGHASTORE,POSSIBLYGROCERYSHOPPINGTHEPRESENCEOFOTHERSHOPPERSANDTHEAISLELAYOUTSUGGESTTHATTHISISANINDOORSETTINGTHEPERSONSEEMSTOBEENGAGEDINTHESHOPPINGPROCESS,CAREFULLYSELECTINGITEMSANDPLACINGTHEMINTHECART\n",
      "The image shows a woman with her hand on another woman's backside. The woman appears to have been groped or touched inappropriately by this stranger, as indicated by the position of her hand and the look of shock or disgust on her face. This is a form of harassment and assault.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_65.jpg / Ollama Result: THEIMAGESHOWSAWOMANWITHHERHANDONANOTHERWOMAN'SBACKSIDETHEWOMANAPPEARSTOHAVEBEENGROPEDORTOUCHEDINAPPROPRIATELYBYTHISSTRANGER,ASINDICATEDBYTHEPOSITIONOFHERHANDANDTHELOOKOFSHOCKORDISGUSTONHERFACETHISISAFORMOFHARASSMENTANDASSAULT\n",
      "The image shows a woman standing in a store, with an arm reaching out to touch her from behind. The purpose of the image is unclear, but it appears to be a candid shot taken by someone else in the store.\n",
      "\n",
      "Here are some key observations about the image:\n",
      "\n",
      "* The woman:\n",
      "\t+ Is wearing a light-colored shirt and pants\n",
      "\t+ Has short white hair\n",
      "\t+ Appears to be middle-aged or older\n",
      "* The arm:\n",
      "\t+ Reaches out from behind the woman, with its hand extended towards her back\n",
      "\t+ Belongs to someone who is not visible in the frame\n",
      "* The background:\n",
      "\t+ Is blurry and indistinct, but appears to show other people shopping in the store\n",
      "\n",
      "Overall, the image suggests that the woman may be being touched or assisted by someone else in the store, perhaps a sales associate or a family member. However, without more context, it is difficult to say for certain what is happening in the image.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_66.jpg / Ollama Result: THEIMAGESHOWSAWOMANSTANDINGINASTORE,WITHANARMREACHINGOUTTOTOUCHHERFROMBEHINDTHEPURPOSEOFTHEIMAGEISUNCLEAR,BUTITAPPEARSTOBEACANDIDSHOTTAKENBYSOMEONEELSEINTHESTORE\n",
      "\n",
      "HEREARESOMEKEYOBSERVATIONSABOUTTHEIMAGE:\n",
      "\n",
      "*THEWOMAN:\n",
      "\t+ISWEARINGALIGHT-COLOREDSHIRTANDPANTS\n",
      "\t+HASSHORTWHITEHAIR\n",
      "\t+APPEARSTOBEMIDDLE-AGEDOROLDER\n",
      "*THEARM:\n",
      "\t+REACHESOUTFROMBEHINDTHEWOMAN,WITHITSHANDEXTENDEDTOWARDSHERBACK\n",
      "\t+BELONGSTOSOMEONEWHOISNOTVISIBLEINTHEFRAME\n",
      "*THEBACKGROUND:\n",
      "\t+ISBLURRYANDINDISTINCT,BUTAPPEARSTOSHOWOTHERPEOPLESHOPPINGINTHESTORE\n",
      "\n",
      "OVERALL,THEIMAGESUGGESTSTHATTHEWOMANMAYBEBEINGTOUCHEDORASSISTEDBYSOMEONEELSEINTHESTORE,PERHAPSASALESASSOCIATEORAFAMILYMEMBERHOWEVER,WITHOUTMORECONTEXT,ITISDIFFICULTTOSAYFORCERTAINWHATISHAPPENINGINTHEIMAGE\n",
      "The image appears to show an older woman with short gray hair, wearing a beige shirt and white pants. She seems to be walking away from someone who has their arm outstretched towards her, possibly trying to get her attention or stop her. The background suggests that she may be in a store or other public place.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_67.jpg / Ollama Result: THEIMAGEAPPEARSTOSHOWANOLDERWOMANWITHSHORTGRAYHAIR,WEARINGABEIGESHIRTANDWHITEPANTSSHESEEMSTOBEWALKINGAWAYFROMSOMEONEWHOHASTHEIRARMOUTSTRETCHEDTOWARDSHER,POSSIBLYTRYINGTOGETHERATTENTIONORSTOPHERTHEBACKGROUNDSUGGESTSTHATSHEMAYBEINASTOREOROTHERPUBLICPLACE\n",
      "The image appears to show an older woman walking in a store with someone's arm around her, possibly helping or guiding her. The exact nature of their relationship is unclear, but based on the context and body language, it seems likely that they are related or have some sort of connection.\n",
      "\n",
      "Here are some possible interpretations:\n",
      "\n",
      "1. **Caregiver or companion**: The person with their arm around the woman may be a caregiver or companion who is helping her navigate the store or perform daily tasks.\n",
      "2. **Family member or friend**: The two individuals may be family members or close friends who are accompanying each other on an outing or errand.\n",
      "3. **Assistance program**: The woman may be part of an assistance program for seniors, and the person with their arm around her is a volunteer or staff member providing support and guidance.\n",
      "\n",
      "It's important to note that without more context or information, it's difficult to say for certain what is happening in the image.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_68.jpg / Ollama Result: THEIMAGEAPPEARSTOSHOWANOLDERWOMANWALKINGINASTOREWITHSOMEONE'SARMAROUNDHER,POSSIBLYHELPINGORGUIDINGHERTHEEXACTNATUREOFTHEIRRELATIONSHIPISUNCLEAR,BUTBASEDONTHECONTEXTANDBODYLANGUAGE,ITSEEMSLIKELYTHATTHEYARERELATEDORHAVESOMESORTOFCONNECTION\n",
      "\n",
      "HEREARESOMEPOSSIBLEINTERPRETATIONS:\n",
      "\n",
      "1**CAREGIVERORCOMPANION**:THEPERSONWITHTHEIRARMAROUNDTHEWOMANMAYBEACAREGIVERORCOMPANIONWHOISHELPINGHERNAVIGATETHESTOREORPERFORMDAILYTASKS\n",
      "2**FAMILYMEMBERORFRIEND**:THETWOINDIVIDUALSMAYBEFAMILYMEMBERSORCLOSEFRIENDSWHOAREACCOMPANYINGEACHOTHERONANOUTINGORERRAND\n",
      "3**ASSISTANCEPROGRAM**:THEWOMANMAYBEPARTOFANASSISTANCEPROGRAMFORSENIORS,ANDTHEPERSONWITHTHEIRARMAROUNDHERISAVOLUNTEERORSTAFFMEMBERPROVIDINGSUPPORTANDGUIDANCE\n",
      "\n",
      "IT'SIMPORTANTTONOTETHATWITHOUTMORECONTEXTORINFORMATION,IT'SDIFFICULTTOSAYFORCERTAINWHATISHAPPENINGINTHEIMAGE\n",
      "The image appears to show an older woman in a shopping environment, possibly a grocery store or retail setting. Here are some observations about her actions and surroundings:\n",
      "\n",
      "**Actions:**\n",
      "\n",
      "* The woman seems to be walking or standing still, with her body facing towards the right side of the image.\n",
      "* Her head is turned slightly towards the left, as if she is looking at something or someone in that direction.\n",
      "* One arm appears to be extended outwards from her body, but it's difficult to determine what she might be holding or doing with her hand.\n",
      "\n",
      "**Surroundings:**\n",
      "\n",
      "* The background of the image shows a blurred view of shelves or racks, which could indicate that she is in a store or retail setting.\n",
      "* There are no other people visible in the immediate vicinity, although there may be others in the distance or behind objects on the shelves.\n",
      "* The overall atmosphere appears to be calm and quiet, with no signs of chaos or urgency.\n",
      "\n",
      "**Additional Observations:**\n",
      "\n",
      "* The woman's clothing and hairstyle suggest that she is likely an older adult, possibly in her 60s or 70s.\n",
      "* Her posture and body language appear relaxed and casual, which could indicate that she is comfortable in her surroundings or engaged in a familiar activity.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_69.jpg / Ollama Result: THEIMAGEAPPEARSTOSHOWANOLDERWOMANINASHOPPINGENVIRONMENT,POSSIBLYAGROCERYSTOREORRETAILSETTINGHEREARESOMEOBSERVATIONSABOUTHERACTIONSANDSURROUNDINGS:\n",
      "\n",
      "**ACTIONS:**\n",
      "\n",
      "*THEWOMANSEEMSTOBEWALKINGORSTANDINGSTILL,WITHHERBODYFACINGTOWARDSTHERIGHTSIDEOFTHEIMAGE\n",
      "*HERHEADISTURNEDSLIGHTLYTOWARDSTHELEFT,ASIFSHEISLOOKINGATSOMETHINGORSOMEONEINTHATDIRECTION\n",
      "*ONEARMAPPEARSTOBEEXTENDEDOUTWARDSFROMHERBODY,BUTIT'SDIFFICULTTODETERMINEWHATSHEMIGHTBEHOLDINGORDOINGWITHHERHAND\n",
      "\n",
      "**SURROUNDINGS:**\n",
      "\n",
      "*THEBACKGROUNDOFTHEIMAGESHOWSABLURREDVIEWOFSHELVESORRACKS,WHICHCOULDINDICATETHATSHEISINASTOREORRETAILSETTING\n",
      "*THEREARENOOTHERPEOPLEVISIBLEINTHEIMMEDIATEVICINITY,ALTHOUGHTHEREMAYBEOTHERSINTHEDISTANCEORBEHINDOBJECTSONTHESHELVES\n",
      "*THEOVERALLATMOSPHEREAPPEARSTOBECALMANDQUIET,WITHNOSIGNSOFCHAOSORURGENCY\n",
      "\n",
      "**ADDITIONALOBSERVATIONS:**\n",
      "\n",
      "*THEWOMAN'SCLOTHINGANDHAIRSTYLESUGGESTTHATSHEISLIKELYANOLDERADULT,POSSIBLYINHER60SOR70S\n",
      "*HERPOSTUREANDBODYLANGUAGEAPPEARRELAXEDANDCASUAL,WHICHCOULDINDICATETHATSHEISCOMFORTABLEINHERSURROUNDINGSORENGAGEDINAFAMILIARACTIVITY\n",
      "The image appears to show a woman standing in an aisle of a store. Her right arm is outstretched, and her hand is grasping what appears to be the forearm of another person. Based on the position of their arms, it seems likely that the two people are shopping together, possibly helping each other carry items or navigating through the store.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_70.jpg / Ollama Result: THEIMAGEAPPEARSTOSHOWAWOMANSTANDINGINANAISLEOFASTOREHERRIGHTARMISOUTSTRETCHED,ANDHERHANDISGRASPINGWHATAPPEARSTOBETHEFOREARMOFANOTHERPERSONBASEDONTHEPOSITIONOFTHEIRARMS,ITSEEMSLIKELYTHATTHETWOPEOPLEARESHOPPINGTOGETHER,POSSIBLYHELPINGEACHOTHERCARRYITEMSORNAVIGATINGTHROUGHTHESTORE\n",
      "The image shows a woman in a grocery store, with her hand reaching out to touch something or someone. Here are some observations about the scene:\n",
      "\n",
      "* The woman has short gray hair and is wearing a beige shirt and white pants.\n",
      "* She is standing in a grocery store, possibly near the produce section given the presence of fruits and vegetables behind her.\n",
      "* Her right arm is extended outward, with her hand reaching out as if to touch or grab something.\n",
      "* It's not clear what she is reaching for, but it could be a product on a shelf, another person, or even a shopping cart.\n",
      "\n",
      "Overall, the image suggests that the woman is engaged in some kind of activity related to grocery shopping, possibly selecting an item from a shelf or interacting with someone else.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_71.jpg / Ollama Result: THEIMAGESHOWSAWOMANINAGROCERYSTORE,WITHHERHANDREACHINGOUTTOTOUCHSOMETHINGORSOMEONEHEREARESOMEOBSERVATIONSABOUTTHESCENE:\n",
      "\n",
      "*THEWOMANHASSHORTGRAYHAIRANDISWEARINGABEIGESHIRTANDWHITEPANTS\n",
      "*SHEISSTANDINGINAGROCERYSTORE,POSSIBLYNEARTHEPRODUCESECTIONGIVENTHEPRESENCEOFFRUITSANDVEGETABLESBEHINDHER\n",
      "*HERRIGHTARMISEXTENDEDOUTWARD,WITHHERHANDREACHINGOUTASIFTOTOUCHORGRABSOMETHING\n",
      "*IT'SNOTCLEARWHATSHEISREACHINGFOR,BUTITCOULDBEAPRODUCTONASHELF,ANOTHERPERSON,OREVENASHOPPINGCART\n",
      "\n",
      "OVERALL,THEIMAGESUGGESTSTHATTHEWOMANISENGAGEDINSOMEKINDOFACTIVITYRELATEDTOGROCERYSHOPPING,POSSIBLYSELECTINGANITEMFROMASHELFORINTERACTINGWITHSOMEONEELSE\n",
      "The individual in the image appears to be using a walker or other mobility device, which suggests they may have difficulty walking or standing on their own. They are holding onto something that provides support and balance as they move through the area where they appear to be grocery shopping. The person could possibly be having trouble with their balance.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_72.jpg / Ollama Result: THEINDIVIDUALINTHEIMAGEAPPEARSTOBEUSINGAWALKEROROTHERMOBILITYDEVICE,WHICHSUGGESTSTHEYMAYHAVEDIFFICULTYWALKINGORSTANDINGONTHEIROWNTHEYAREHOLDINGONTOSOMETHINGTHATPROVIDESSUPPORTANDBALANCEASTHEYMOVETHROUGHTHEAREAWHERETHEYAPPEARTOBEGROCERYSHOPPINGTHEPERSONCOULDPOSSIBLYBEHAVINGTROUBLEWITHTHEIRBALANCE\n",
      "The individual depicted in the image appears to be dancing or performing a choreographed routine, as evidenced by their dynamic posture and arm movements. Their right leg is bent at the knee, while their left leg remains straight, with their foot pointed outward. The individual's arms are extended outward from their body, with their hands open and palms facing downward.\n",
      "\n",
      "The individual seems to be enjoying themselves, as they appear to be smiling and laughing. The fact that they are performing in a public setting, such as a grocery store, suggests that they may be attempting to entertain or interact with others around them.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_73.jpg / Ollama Result: THEINDIVIDUALDEPICTEDINTHEIMAGEAPPEARSTOBEDANCINGORPERFORMINGACHOREOGRAPHEDROUTINE,ASEVIDENCEDBYTHEIRDYNAMICPOSTUREANDARMMOVEMENTSTHEIRRIGHTLEGISBENTATTHEKNEE,WHILETHEIRLEFTLEGREMAINSSTRAIGHT,WITHTHEIRFOOTPOINTEDOUTWARDTHEINDIVIDUAL'SARMSAREEXTENDEDOUTWARDFROMTHEIRBODY,WITHTHEIRHANDSOPENANDPALMSFACINGDOWNWARD\n",
      "\n",
      "THEINDIVIDUALSEEMSTOBEENJOYINGTHEMSELVES,ASTHEYAPPEARTOBESMILINGANDLAUGHINGTHEFACTTHATTHEYAREPERFORMINGINAPUBLICSETTING,SUCHASAGROCERYSTORE,SUGGESTSTHATTHEYMAYBEATTEMPTINGTOENTERTAINORINTERACTWITHOTHERSAROUNDTHEM\n",
      "The person depicted in the image appears to be shopping in a grocery store, as evidenced by the cart of groceries behind them. They are likely selecting items from the shelves, as their hands appear to be reaching out towards the products. The person's posture and body language suggest that they are engaged in the act of shopping, carefully considering which items to purchase.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_74.jpg / Ollama Result: THEPERSONDEPICTEDINTHEIMAGEAPPEARSTOBESHOPPINGINAGROCERYSTORE,ASEVIDENCEDBYTHECARTOFGROCERIESBEHINDTHEMTHEYARELIKELYSELECTINGITEMSFROMTHESHELVES,ASTHEIRHANDSAPPEARTOBEREACHINGOUTTOWARDSTHEPRODUCTSTHEPERSON'SPOSTUREANDBODYLANGUAGESUGGESTTHATTHEYAREENGAGEDINTHEACTOFSHOPPING,CAREFULLYCONSIDERINGWHICHITEMSTOPURCHASE\n",
      "The image appears to show an older woman, perhaps elderly, with grey hair and glasses. She is dressed in a white t-shirt and pants with white shoes, and has a green object attached to her waistband. The woman appears to be dancing or posing in a shopping aisle or similar setting, with what appear to be shelves of products in the background. Her arms are bent at the elbows, her knees slightly bent, and she seems to be moving from side to side.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_75.jpg / Ollama Result: THEIMAGEAPPEARSTOSHOWANOLDERWOMAN,PERHAPSELDERLY,WITHGREYHAIRANDGLASSESSHEISDRESSEDINAWHITET-SHIRTANDPANTSWITHWHITESHOES,ANDHASAGREENOBJECTATTACHEDTOHERWAISTBANDTHEWOMANAPPEARSTOBEDANCINGORPOSINGINASHOPPINGAISLEORSIMILARSETTING,WITHWHATAPPEARTOBESHELVESOFPRODUCTSINTHEBACKGROUNDHERARMSAREBENTATTHEELBOWS,HERKNEESSLIGHTLYBENT,ANDSHESEEMSTOBEMOVINGFROMSIDETOSIDE\n",
      "The individual depicted in the image appears to be dancing or performing some form of rhythmic movement. Their right arm is bent at the elbow and held out to the side, while their left arm is extended behind them, with their hand nearly touching the floor. The woman's torso is turned slightly to her right, and she seems to have one foot in front of the other, suggesting that she may be performing a step or tap dance.\n",
      "\n",
      "The image quality does not allow for a clear view of their feet, but based on the position of their legs and body, it appears that they are moving in a fluid, rhythmic manner. The woman's facial expression is also worth noting, as she seems to be fully engaged with the music and her surroundings. Her eyes appear to be closed or slightly cast downward, suggesting that she is focusing intently on the movement and rhythm of the dance.\n",
      "\n",
      "Overall, based on the position and orientation of their body, it appears that this individual is performing a form of rhythmic movement, possibly a tap dance or step routine.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_76.jpg / Ollama Result: THEINDIVIDUALDEPICTEDINTHEIMAGEAPPEARSTOBEDANCINGORPERFORMINGSOMEFORMOFRHYTHMICMOVEMENTTHEIRRIGHTARMISBENTATTHEELBOWANDHELDOUTTOTHESIDE,WHILETHEIRLEFTARMISEXTENDEDBEHINDTHEM,WITHTHEIRHANDNEARLYTOUCHINGTHEFLOORTHEWOMAN'STORSOISTURNEDSLIGHTLYTOHERRIGHT,ANDSHESEEMSTOHAVEONEFOOTINFRONTOFTHEOTHER,SUGGESTINGTHATSHEMAYBEPERFORMINGASTEPORTAPDANCE\n",
      "\n",
      "THEIMAGEQUALITYDOESNOTALLOWFORACLEARVIEWOFTHEIRFEET,BUTBASEDONTHEPOSITIONOFTHEIRLEGSANDBODY,ITAPPEARSTHATTHEYAREMOVINGINAFLUID,RHYTHMICMANNERTHEWOMAN'SFACIALEXPRESSIONISALSOWORTHNOTING,ASSHESEEMSTOBEFULLYENGAGEDWITHTHEMUSICANDHERSURROUNDINGSHEREYESAPPEARTOBECLOSEDORSLIGHTLYCASTDOWNWARD,SUGGESTINGTHATSHEISFOCUSINGINTENTLYONTHEMOVEMENTANDRHYTHMOFTHEDANCE\n",
      "\n",
      "OVERALL,BASEDONTHEPOSITIONANDORIENTATIONOFTHEIRBODY,ITAPPEARSTHATTHISINDIVIDUALISPERFORMINGAFORMOFRHYTHMICMOVEMENT,POSSIBLYATAPDANCEORSTEPROUTINE\n",
      "The individual appears to be dancing in a store. Their arms are raised and bent, their legs are spread apart, and they appear to be moving their feet as if they are performing some sort of dance move. The background suggests that this may be a grocery store or supermarket, which indicates that the person is likely shopping or has finished shopping and is now dancing for fun.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_77.jpg / Ollama Result: THEINDIVIDUALAPPEARSTOBEDANCINGINASTORETHEIRARMSARERAISEDANDBENT,THEIRLEGSARESPREADAPART,ANDTHEYAPPEARTOBEMOVINGTHEIRFEETASIFTHEYAREPERFORMINGSOMESORTOFDANCEMOVETHEBACKGROUNDSUGGESTSTHATTHISMAYBEAGROCERYSTOREORSUPERMARKET,WHICHINDICATESTHATTHEPERSONISLIKELYSHOPPINGORHASFINISHEDSHOPPINGANDISNOWDANCINGFORFUN\n",
      "Based on the image, it appears that the woman is dancing in a grocery store. She has her arms outstretched and her hips moving to an unseen beat. Her facial expression suggests she is enjoying herself and having fun. The fact that she is dancing in the middle of a grocery store is likely because she is listening to music or watching something on a phone or tablet, and she feels comfortable enough to let loose and dance. It's possible that she is trying to spread some joy and positivity by dancing, which can be contagious and bring smiles to the faces of others around her.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_78.jpg / Ollama Result: BASEDONTHEIMAGE,ITAPPEARSTHATTHEWOMANISDANCINGINAGROCERYSTORESHEHASHERARMSOUTSTRETCHEDANDHERHIPSMOVINGTOANUNSEENBEATHERFACIALEXPRESSIONSUGGESTSSHEISENJOYINGHERSELFANDHAVINGFUNTHEFACTTHATSHEISDANCINGINTHEMIDDLEOFAGROCERYSTOREISLIKELYBECAUSESHEISLISTENINGTOMUSICORWATCHINGSOMETHINGONAPHONEORTABLET,ANDSHEFEELSCOMFORTABLEENOUGHTOLETLOOSEANDDANCEIT'SPOSSIBLETHATSHEISTRYINGTOSPREADSOMEJOYANDPOSITIVITYBYDANCING,WHICHCANBECONTAGIOUSANDBRINGSMILESTOTHEFACESOFOTHERSAROUNDHER\n",
      "The woman appears to be dancing or posing for a photo, as evidenced by her bent knees and arms outstretched behind her. She is likely in a store or public place, possibly during an event or celebration such as a birthday party.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_79.jpg / Ollama Result: THEWOMANAPPEARSTOBEDANCINGORPOSINGFORAPHOTO,ASEVIDENCEDBYHERBENTKNEESANDARMSOUTSTRETCHEDBEHINDHERSHEISLIKELYINASTOREORPUBLICPLACE,POSSIBLYDURINGANEVENTORCELEBRATIONSUCHASABIRTHDAYPARTY\n",
      "The woman appears to be dancing while in a grocery store. She is holding her arms out to either side and has one leg bent at the knee, as if she is performing some sort of dance move. Her facial expression suggests that she is enjoying herself and having fun.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_80.jpg / Ollama Result: THEWOMANAPPEARSTOBEDANCINGWHILEINAGROCERYSTORESHEISHOLDINGHERARMSOUTTOEITHERSIDEANDHASONELEGBENTATTHEKNEE,ASIFSHEISPERFORMINGSOMESORTOFDANCEMOVEHERFACIALEXPRESSIONSUGGESTSTHATSHEISENJOYINGHERSELFANDHAVINGFUN\n",
      "The individual in the image appears to be dancing or moving around in a playful manner, possibly attempting to get someone's attention or simply enjoying themselves in a public setting. It's important to note that without more context, it's difficult to determine the exact nature of their behavior.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_81.jpg / Ollama Result: THEINDIVIDUALINTHEIMAGEAPPEARSTOBEDANCINGORMOVINGAROUNDINAPLAYFULMANNER,POSSIBLYATTEMPTINGTOGETSOMEONE'SATTENTIONORSIMPLYENJOYINGTHEMSELVESINAPUBLICSETTINGIT'SIMPORTANTTONOTETHATWITHOUTMORECONTEXT,IT'SDIFFICULTTODETERMINETHEEXACTNATUREOFTHEIRBEHAVIOR\n",
      "The individual depicted in the image appears to be dancing or moving around a store, possibly in a shopping mall. The background of the photo is out of focus, but it appears to show a grocery store and other shoppers.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_82.jpg / Ollama Result: THEINDIVIDUALDEPICTEDINTHEIMAGEAPPEARSTOBEDANCINGORMOVINGAROUNDASTORE,POSSIBLYINASHOPPINGMALLTHEBACKGROUNDOFTHEPHOTOISOUTOFFOCUS,BUTITAPPEARSTOSHOWAGROCERYSTOREANDOTHERSHOPPERS\n",
      "The person in the image appears to be dancing or moving around in a store. Their right arm is bent at the elbow and their left arm is extended outwards, while their left leg is lifted off the ground, with their foot pointing towards the floor. The person's head is turned away from the camera, and they appear to be looking down at something on the floor.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_83.jpg / Ollama Result: THEPERSONINTHEIMAGEAPPEARSTOBEDANCINGORMOVINGAROUNDINASTORETHEIRRIGHTARMISBENTATTHEELBOWANDTHEIRLEFTARMISEXTENDEDOUTWARDS,WHILETHEIRLEFTLEGISLIFTEDOFFTHEGROUND,WITHTHEIRFOOTPOINTINGTOWARDSTHEFLOORTHEPERSON'SHEADISTURNEDAWAYFROMTHECAMERA,ANDTHEYAPPEARTOBELOOKINGDOWNATSOMETHINGONTHEFLOOR\n",
      "The individual in the image appears to be engaged in a form of exercise or stretching, possibly in preparation for physical activity. The following observations support this assessment:\n",
      "\n",
      "* The person's arms are bent at the elbows and held close to their body.\n",
      "* Their right leg is extended behind them, while their left leg remains planted firmly on the ground.\n",
      "\n",
      "This stance suggests that the individual is preparing to perform a lunge or some other form of lower-body exercise.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_84.jpg / Ollama Result: THEINDIVIDUALINTHEIMAGEAPPEARSTOBEENGAGEDINAFORMOFEXERCISEORSTRETCHING,POSSIBLYINPREPARATIONFORPHYSICALACTIVITYTHEFOLLOWINGOBSERVATIONSSUPPORTTHISASSESSMENT:\n",
      "\n",
      "*THEPERSON'SARMSAREBENTATTHEELBOWSANDHELDCLOSETOTHEIRBODY\n",
      "*THEIRRIGHTLEGISEXTENDEDBEHINDTHEM,WHILETHEIRLEFTLEGREMAINSPLANTEDFIRMLYONTHEGROUND\n",
      "\n",
      "THISSTANCESUGGESTSTHATTHEINDIVIDUALISPREPARINGTOPERFORMALUNGEORSOMEOTHERFORMOFLOWER-BODYEXERCISE\n",
      "The individual in question appears to be engaged in a unique form of self-expression or perhaps attempting to communicate with others, as evidenced by their distinctive stance and posture. Key aspects of their behavior include:\n",
      "\n",
      "* A pronounced bending of the knees\n",
      "* A leaning forward motion, which may suggest an attempt to convey a message or draw attention to themselves\n",
      "\n",
      "This behavior could be interpreted in various ways, such as:\n",
      "\n",
      "* Attempting to communicate with others\n",
      "* Expressing themselves through dance or other forms of self-expression\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_85.jpg / Ollama Result: THEINDIVIDUALINQUESTIONAPPEARSTOBEENGAGEDINAUNIQUEFORMOFSELF-EXPRESSIONORPERHAPSATTEMPTINGTOCOMMUNICATEWITHOTHERS,ASEVIDENCEDBYTHEIRDISTINCTIVESTANCEANDPOSTUREKEYASPECTSOFTHEIRBEHAVIORINCLUDE:\n",
      "\n",
      "*APRONOUNCEDBENDINGOFTHEKNEES\n",
      "*ALEANINGFORWARDMOTION,WHICHMAYSUGGESTANATTEMPTTOCONVEYAMESSAGEORDRAWATTENTIONTOTHEMSELVES\n",
      "\n",
      "THISBEHAVIORCOULDBEINTERPRETEDINVARIOUSWAYS,SUCHAS:\n",
      "\n",
      "*ATTEMPTINGTOCOMMUNICATEWITHOTHERS\n",
      "*EXPRESSINGTHEMSELVESTHROUGHDANCEOROTHERFORMSOFSELF-EXPRESSION\n",
      "It appears that this individual is shopping at a store, perhaps Walmart given the presence of a shopping cart in the background. The person seems to be browsing through various products and has their arms outstretched for balance while looking down at something they are interested in. They appear to be wearing a back pack on their shoulders.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_86.jpg / Ollama Result: ITAPPEARSTHATTHISINDIVIDUALISSHOPPINGATASTORE,PERHAPSWALMARTGIVENTHEPRESENCEOFASHOPPINGCARTINTHEBACKGROUNDTHEPERSONSEEMSTOBEBROWSINGTHROUGHVARIOUSPRODUCTSANDHASTHEIRARMSOUTSTRETCHEDFORBALANCEWHILELOOKINGDOWNATSOMETHINGTHEYAREINTERESTEDINTHEYAPPEARTOBEWEARINGABACKPACKONTHEIRSHOULDERS\n",
      "The individual appears to be in a shopping center or mall, facing away from the camera. They seem to be engaged with someone on their right side, possibly conversing or sharing something. The person has their arms outstretched, which could indicate they are discussing or gesturing towards an object of interest nearby.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_87.jpg / Ollama Result: THEINDIVIDUALAPPEARSTOBEINASHOPPINGCENTERORMALL,FACINGAWAYFROMTHECAMERATHEYSEEMTOBEENGAGEDWITHSOMEONEONTHEIRRIGHTSIDE,POSSIBLYCONVERSINGORSHARINGSOMETHINGTHEPERSONHASTHEIRARMSOUTSTRETCHED,WHICHCOULDINDICATETHEYAREDISCUSSINGORGESTURINGTOWARDSANOBJECTOFINTERESTNEARBY\n",
      "The individual in the image appears to be dancing or performing some form of movement, possibly as part of a performance or for entertainment. Their body language suggests they are using their arms and legs to create a dynamic and expressive gesture, while wearing a backpack that may indicate they are traveling or carrying supplies. The image captures a moment of freedom and joy, with the person seemingly lost in the rhythm of their movement.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_88.jpg / Ollama Result: THEINDIVIDUALINTHEIMAGEAPPEARSTOBEDANCINGORPERFORMINGSOMEFORMOFMOVEMENT,POSSIBLYASPARTOFAPERFORMANCEORFORENTERTAINMENTTHEIRBODYLANGUAGESUGGESTSTHEYAREUSINGTHEIRARMSANDLEGSTOCREATEADYNAMICANDEXPRESSIVEGESTURE,WHILEWEARINGABACKPACKTHATMAYINDICATETHEYARETRAVELINGORCARRYINGSUPPLIESTHEIMAGECAPTURESAMOMENTOFFREEDOMANDJOY,WITHTHEPERSONSEEMINGLYLOSTINTHERHYTHMOFTHEIRMOVEMENT\n",
      "The individual appears to be dancing in a shopping centre, as evidenced by their arms outstretched and feet tapping. It seems that they are alone, without any other people nearby, which contributes to the carefree atmosphere of their dance. The setting, with its polished concrete floor and subtle lighting, suggests that the person is likely dancing for fun or to express themselves creatively in a public space. Their attire, consisting of a red hat, black tank top, black pants, and red Crocs, adds to the playful and casual nature of the scene. Overall, it seems as though they are simply enjoying themselves and letting loose in a moment of unbridled joy.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_89.jpg / Ollama Result: THEINDIVIDUALAPPEARSTOBEDANCINGINASHOPPINGCENTRE,ASEVIDENCEDBYTHEIRARMSOUTSTRETCHEDANDFEETTAPPINGITSEEMSTHATTHEYAREALONE,WITHOUTANYOTHERPEOPLENEARBY,WHICHCONTRIBUTESTOTHECAREFREEATMOSPHEREOFTHEIRDANCETHESETTING,WITHITSPOLISHEDCONCRETEFLOORANDSUBTLELIGHTING,SUGGESTSTHATTHEPERSONISLIKELYDANCINGFORFUNORTOEXPRESSTHEMSELVESCREATIVELYINAPUBLICSPACETHEIRATTIRE,CONSISTINGOFAREDHAT,BLACKTANKTOP,BLACKPANTS,ANDREDCROCS,ADDSTOTHEPLAYFULANDCASUALNATUREOFTHESCENEOVERALL,ITSEEMSASTHOUGHTHEYARESIMPLYENJOYINGTHEMSELVESANDLETTINGLOOSEINAMOMENTOFUNBRIDLEDJOY\n",
      "The person in the image appears to be shopping or browsing in a store, as evidenced by their position facing the shelves and racks of merchandise. They seem to be taking a moment to look around and perhaps decide on something they want to purchase. The person's posture suggests that they are relaxed and comfortable with their surroundings, indicating that they may have been in the store for some time or feel at ease there.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_90.jpg / Ollama Result: THEPERSONINTHEIMAGEAPPEARSTOBESHOPPINGORBROWSINGINASTORE,ASEVIDENCEDBYTHEIRPOSITIONFACINGTHESHELVESANDRACKSOFMERCHANDISETHEYSEEMTOBETAKINGAMOMENTTOLOOKAROUNDANDPERHAPSDECIDEONSOMETHINGTHEYWANTTOPURCHASETHEPERSON'SPOSTURESUGGESTSTHATTHEYARERELAXEDANDCOMFORTABLEWITHTHEIRSURROUNDINGS,INDICATINGTHATTHEYMAYHAVEBEENINTHESTOREFORSOMETIMEORFEELATEASETHERE\n",
      "The individual appears to be using their phone to take a picture or video of themselves, as evidenced by the fact that they are holding it up in front of them. The device's screen is also likely visible, suggesting that they are using it for its intended purpose.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_91.jpg / Ollama Result: THEINDIVIDUALAPPEARSTOBEUSINGTHEIRPHONETOTAKEAPICTUREORVIDEOOFTHEMSELVES,ASEVIDENCEDBYTHEFACTTHATTHEYAREHOLDINGITUPINFRONTOFTHEMTHEDEVICE'SSCREENISALSOLIKELYVISIBLE,SUGGESTINGTHATTHEYAREUSINGITFORITSINTENDEDPURPOSE\n",
      "The individual depicted in the image appears to be dancing or performing a celebratory gesture, possibly in response to an exciting event or accomplishment. The person's posture and movements suggest a sense of joy and enthusiasm, with their arms outstretched and body swaying to an unseen rhythm.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_92.jpg / Ollama Result: THEINDIVIDUALDEPICTEDINTHEIMAGEAPPEARSTOBEDANCINGORPERFORMINGACELEBRATORYGESTURE,POSSIBLYINRESPONSETOANEXCITINGEVENTORACCOMPLISHMENTTHEPERSON'SPOSTUREANDMOVEMENTSSUGGESTASENSEOFJOYANDENTHUSIASM,WITHTHEIRARMSOUTSTRETCHEDANDBODYSWAYINGTOANUNSEENRHYTHM\n",
      "The person in this image appears to be dancing, perhaps unaware that they are being recorded on someone's phone. The individual seems to be moving their arms and hips as if they were performing a popular song or dance challenge. Their posture, hand movements, and footwork suggest they are trying to entertain themselves or others around them.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_93.jpg / Ollama Result: THEPERSONINTHISIMAGEAPPEARSTOBEDANCING,PERHAPSUNAWARETHATTHEYAREBEINGRECORDEDONSOMEONE'SPHONETHEINDIVIDUALSEEMSTOBEMOVINGTHEIRARMSANDHIPSASIFTHEYWEREPERFORMINGAPOPULARSONGORDANCECHALLENGETHEIRPOSTURE,HANDMOVEMENTS,ANDFOOTWORKSUGGESTTHEYARETRYINGTOENTERTAINTHEMSELVESOROTHERSAROUNDTHEM\n",
      "The individual in question appears to be engaged in a form of dance, characterized by their raised arms and bent knees. Their body language suggests that they are moving in time with an unseen rhythm or beat, possibly to music played over speakers or headphones not visible in this image. The casual attire, including the red cap and crocs, along with their energetic posture, further supports the inference that they are dancing.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_94.jpg / Ollama Result: THEINDIVIDUALINQUESTIONAPPEARSTOBEENGAGEDINAFORMOFDANCE,CHARACTERIZEDBYTHEIRRAISEDARMSANDBENTKNEESTHEIRBODYLANGUAGESUGGESTSTHATTHEYAREMOVINGINTIMEWITHANUNSEENRHYTHMORBEAT,POSSIBLYTOMUSICPLAYEDOVERSPEAKERSORHEADPHONESNOTVISIBLEINTHISIMAGETHECASUALATTIRE,INCLUDINGTHEREDCAPANDCROCS,ALONGWITHTHEIRENERGETICPOSTURE,FURTHERSUPPORTSTHEINFERENCETHATTHEYAREDANCING\n",
      "The person in the image appears to be in a shopping environment, possibly a grocery store or supermarket. They are walking down an aisle and appear to have their phone in hand. Based on their body language and the items visible in the background, it seems likely that they are engaged in some form of shopping activity, perhaps browsing through products or checking prices on their phone.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_95.jpg / Ollama Result: THEPERSONINTHEIMAGEAPPEARSTOBEINASHOPPINGENVIRONMENT,POSSIBLYAGROCERYSTOREORSUPERMARKETTHEYAREWALKINGDOWNANAISLEANDAPPEARTOHAVETHEIRPHONEINHANDBASEDONTHEIRBODYLANGUAGEANDTHEITEMSVISIBLEINTHEBACKGROUND,ITSEEMSLIKELYTHATTHEYAREENGAGEDINSOMEFORMOFSHOPPINGACTIVITY,PERHAPSBROWSINGTHROUGHPRODUCTSORCHECKINGPRICESONTHEIRPHONE\n",
      "The person in the image appears to be assisting or supporting an elderly woman, likely a family member or caregiver. The person's arm is around the woman's back, and their other hand is holding onto her right elbow, which suggests that they are helping her to walk or stand up. This could be necessary due to the woman's age or mobility issues, as she appears to have some difficulty walking on her own.\n",
      "\n",
      "It's important to note that without more context, it's difficult to say for certain what is happening in this image. However, based on the physical contact and support being provided by the person, it seems likely that they are helping the woman with a task or activity that requires assistance.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_96.jpg / Ollama Result: THEPERSONINTHEIMAGEAPPEARSTOBEASSISTINGORSUPPORTINGANELDERLYWOMAN,LIKELYAFAMILYMEMBERORCAREGIVERTHEPERSON'SARMISAROUNDTHEWOMAN'SBACK,ANDTHEIROTHERHANDISHOLDINGONTOHERRIGHTELBOW,WHICHSUGGESTSTHATTHEYAREHELPINGHERTOWALKORSTANDUPTHISCOULDBENECESSARYDUETOTHEWOMAN'SAGEORMOBILITYISSUES,ASSHEAPPEARSTOHAVESOMEDIFFICULTYWALKINGONHEROWN\n",
      "\n",
      "IT'SIMPORTANTTONOTETHATWITHOUTMORECONTEXT,IT'SDIFFICULTTOSAYFORCERTAINWHATISHAPPENINGINTHISIMAGEHOWEVER,BASEDONTHEPHYSICALCONTACTANDSUPPORTBEINGPROVIDEDBYTHEPERSON,ITSEEMSLIKELYTHATTHEYAREHELPINGTHEWOMANWITHATASKORACTIVITYTHATREQUIRESASSISTANCE\n",
      "The individual in the image appears to be dancing or posing in a grocery store. They are standing with their legs apart and arms raised, as if they are performing some sort of dance move. It's possible that they were caught in the middle of a spontaneous dance session or simply striking a pose for a photo.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_97.jpg / Ollama Result: THEINDIVIDUALINTHEIMAGEAPPEARSTOBEDANCINGORPOSINGINAGROCERYSTORETHEYARESTANDINGWITHTHEIRLEGSAPARTANDARMSRAISED,ASIFTHEYAREPERFORMINGSOMESORTOFDANCEMOVEIT'SPOSSIBLETHATTHEYWERECAUGHTINTHEMIDDLEOFASPONTANEOUSDANCESESSIONORSIMPLYSTRIKINGAPOSEFORAPHOTO\n",
      "The person appears to be dancing in a store. The individual has their left arm bent at the elbow and extended behind them, while their right arm is held straight out from their body. Their head is turned towards the left side of the image, and they are wearing red Crocs with yellow trim.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_98.jpg / Ollama Result: THEPERSONAPPEARSTOBEDANCINGINASTORETHEINDIVIDUALHASTHEIRLEFTARMBENTATTHEELBOWANDEXTENDEDBEHINDTHEM,WHILETHEIRRIGHTARMISHELDSTRAIGHTOUTFROMTHEIRBODYTHEIRHEADISTURNEDTOWARDSTHELEFTSIDEOFTHEIMAGE,ANDTHEYAREWEARINGREDCROCSWITHYELLOWTRIM\n",
      "The individual appears to be shopping in a store, possibly browsing for items or searching for specific products. The act of walking through an aisle and looking at merchandise is a common behavior among shoppers.\n",
      "/app/yolo_structure/results/frame_img/dancing_PERSON_1_99.jpg / Ollama Result: THEINDIVIDUALAPPEARSTOBESHOPPINGINASTORE,POSSIBLYBROWSINGFORITEMSORSEARCHINGFORSPECIFICPRODUCTSTHEACTOFWALKINGTHROUGHANAISLEANDLOOKINGATMERCHANDISEISACOMMONBEHAVIORAMONGSHOPPERS\n"
     ]
    }
   ],
   "source": [
    "llm_res_l = []\n",
    "for index,value in df_filtered_person.iterrows():\n",
    "    if value[\"detected\"] !=\"person\":\n",
    "        llm_res_l.append(value[\"detected\"])\n",
    "        continue\n",
    "    try:\n",
    "        crop_filename = os.path.join(crop_save_dir,value[\"frame_hash\"]+\"_\"+ str(value[\"frame_num\"]) +\".jpg\")\n",
    "        res = ollama.chat(\n",
    "            model= \"llama3.2-vision:11b\",\n",
    "            messages=[\n",
    "                {\n",
    "                    'role': 'user',\n",
    "                    'content': \"tell me what is the person doing\",\n",
    "                    'images': [crop_filename]\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        print(res['message']['content'])\n",
    "    except:\n",
    "       continue\n",
    "\n",
    "    final_result = res['message']['content'].upper().replace(\".\",\"\").replace(\" \",\"\")\n",
    "    print(f\"{crop_filename} / Ollama Result: {final_result}\")\n",
    "    llm_res_l.append(final_result)\n",
    "df_filtered_person[\"llm_res\"] = llm_res_l\n",
    "df_filtered_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ab4c0b4-362e-454d-8c42-8e5e292e733a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>distance</th>\n",
       "      <th>event</th>\n",
       "      <th>detected</th>\n",
       "      <th>source_name</th>\n",
       "      <th>frame_hash</th>\n",
       "      <th>frame_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>20250203-165515</td>\n",
       "      <td>0</td>\n",
       "      <td>STOP</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_STOP_1</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>20250203-165515</td>\n",
       "      <td>0</td>\n",
       "      <td>STOP</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_STOP_1</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>20250203-165515</td>\n",
       "      <td>0</td>\n",
       "      <td>STOP</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_STOP_1</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>20250203-165515</td>\n",
       "      <td>0</td>\n",
       "      <td>STOP</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_STOP_1</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>20250203-165515</td>\n",
       "      <td>0</td>\n",
       "      <td>STOP</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_STOP_1</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>20250203-165559</td>\n",
       "      <td>0</td>\n",
       "      <td>STOP</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_STOP_5</td>\n",
       "      <td>1784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>20250203-165559</td>\n",
       "      <td>0</td>\n",
       "      <td>STOP</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_STOP_5</td>\n",
       "      <td>1785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>20250203-165559</td>\n",
       "      <td>0</td>\n",
       "      <td>STOP</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_STOP_5</td>\n",
       "      <td>1786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>20250203-165559</td>\n",
       "      <td>0</td>\n",
       "      <td>STOP</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_STOP_5</td>\n",
       "      <td>1787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>20250203-165559</td>\n",
       "      <td>0</td>\n",
       "      <td>STOP</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_STOP_5</td>\n",
       "      <td>1788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>407 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            datetime  distance event detected     source_name      frame_hash  \\\n",
       "48   20250203-165515         0  STOP      car  cctv001.stream  cctv001_STOP_1   \n",
       "49   20250203-165515         0  STOP      car  cctv001.stream  cctv001_STOP_1   \n",
       "50   20250203-165515         0  STOP      car  cctv001.stream  cctv001_STOP_1   \n",
       "51   20250203-165515         0  STOP      car  cctv001.stream  cctv001_STOP_1   \n",
       "52   20250203-165515         0  STOP      car  cctv001.stream  cctv001_STOP_1   \n",
       "..               ...       ...   ...      ...             ...             ...   \n",
       "144  20250203-165559         0  STOP      car  cctv001.stream  cctv001_STOP_5   \n",
       "145  20250203-165559         0  STOP      car  cctv001.stream  cctv001_STOP_5   \n",
       "146  20250203-165559         0  STOP      car  cctv001.stream  cctv001_STOP_5   \n",
       "147  20250203-165559         0  STOP      car  cctv001.stream  cctv001_STOP_5   \n",
       "148  20250203-165559         0  STOP      car  cctv001.stream  cctv001_STOP_5   \n",
       "\n",
       "     frame_num  \n",
       "48         466  \n",
       "49         467  \n",
       "50         468  \n",
       "51         469  \n",
       "52         470  \n",
       "..         ...  \n",
       "144       1784  \n",
       "145       1785  \n",
       "146       1786  \n",
       "147       1787  \n",
       "148       1788  \n",
       "\n",
       "[407 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frame_hash별로 그룹핑하고, 1초 이내 5개 이상 존재하는 경우 찾기\n",
    "df_raw_stop = df_raw[df_raw[\"event\"] == \"STOP\"]\n",
    "df_raw_stop\n",
    "\n",
    "# frame_hash별로 그룹화 후 frame_num 연속성 확인\n",
    "df_filtered_stop = pd.DataFrame()\n",
    "\n",
    "grouped = df_raw_stop.groupby(\"frame_hash\")\n",
    "for _, group in grouped:\n",
    "    group = group.sort_values(by=\"frame_num\").reset_index(drop=True)\n",
    "    group[\"diff\"] = group[\"frame_num\"].diff().fillna(1)\n",
    "    group[\"consec_group\"] = (group[\"diff\"] != 1).cumsum()\n",
    "    valid_groups = group.groupby(\"consec_group\").filter(lambda x: len(x) >= 5)\n",
    "    df_filtered_stop = pd.concat([df_filtered_stop, valid_groups.drop(columns=[\"diff\", \"consec_group\"])])\n",
    "\n",
    "# 결과 출력\n",
    "df_filtered_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d536a6b-aaec-40ea-aedc-4c4401858ed1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>distance</th>\n",
       "      <th>event</th>\n",
       "      <th>detected</th>\n",
       "      <th>source_name</th>\n",
       "      <th>frame_hash</th>\n",
       "      <th>frame_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>20250204-163610</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_1</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>20250204-163610</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_1</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>20250204-163610</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_1</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20250204-163606</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_2</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20250204-163606</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_2</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>20250204-163606</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_2</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>20250204-163635</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_2</td>\n",
       "      <td>1325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>20250204-163635</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_2</td>\n",
       "      <td>1326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>20250204-163635</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_2</td>\n",
       "      <td>1327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>20250204-163613</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_3</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>20250204-163613</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_3</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>20250204-163613</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_3</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20250204-163606</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_4</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>20250204-163606</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_4</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>20250204-163606</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_4</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>20250204-163607</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_4</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>20250204-163607</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_4</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>20250204-163607</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>bus</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_4</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>20250204-163624</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_5</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>20250204-163624</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_5</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>20250204-163624</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_5</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20250204-163605</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>truck</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_6</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20250204-163605</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_6</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20250204-163605</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_6</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20250204-163605</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_7</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20250204-163605</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_7</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20250204-163605</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_7</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20250204-163605</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_7</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20250204-163605</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_7</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20250204-163605</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_7</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>20250204-163605</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>truck</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_7</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20250204-163605</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_7</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>20250204-163605</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_7</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>20250204-163605</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>truck</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_7</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20250204-163605</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_8</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20250204-163605</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_8</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20250204-163605</td>\n",
       "      <td>0</td>\n",
       "      <td>REVERSE</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_REVERSE_8</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            datetime  distance    event detected     source_name  \\\n",
       "67   20250204-163610         0  REVERSE      car  cctv001.stream   \n",
       "68   20250204-163610         0  REVERSE      car  cctv001.stream   \n",
       "69   20250204-163610         0  REVERSE      car  cctv001.stream   \n",
       "29   20250204-163606         0  REVERSE      car  cctv001.stream   \n",
       "30   20250204-163606         0  REVERSE      car  cctv001.stream   \n",
       "31   20250204-163606         0  REVERSE      car  cctv001.stream   \n",
       "254  20250204-163635         0  REVERSE      car  cctv001.stream   \n",
       "255  20250204-163635         0  REVERSE      car  cctv001.stream   \n",
       "256  20250204-163635         0  REVERSE      car  cctv001.stream   \n",
       "168  20250204-163613         0  REVERSE      car  cctv001.stream   \n",
       "169  20250204-163613         0  REVERSE      car  cctv001.stream   \n",
       "170  20250204-163613         0  REVERSE      car  cctv001.stream   \n",
       "38   20250204-163606         0  REVERSE      car  cctv001.stream   \n",
       "39   20250204-163606         0  REVERSE      car  cctv001.stream   \n",
       "40   20250204-163606         0  REVERSE      car  cctv001.stream   \n",
       "73   20250204-163607         0  REVERSE      car  cctv001.stream   \n",
       "74   20250204-163607         0  REVERSE      car  cctv001.stream   \n",
       "75   20250204-163607         0  REVERSE      bus  cctv001.stream   \n",
       "280  20250204-163624         0  REVERSE      car  cctv001.stream   \n",
       "281  20250204-163624         0  REVERSE      car  cctv001.stream   \n",
       "282  20250204-163624         0  REVERSE      car  cctv001.stream   \n",
       "13   20250204-163605         0  REVERSE    truck  cctv001.stream   \n",
       "14   20250204-163605         0  REVERSE      car  cctv001.stream   \n",
       "15   20250204-163605         0  REVERSE      car  cctv001.stream   \n",
       "24   20250204-163605         0  REVERSE      car  cctv001.stream   \n",
       "25   20250204-163605         0  REVERSE      car  cctv001.stream   \n",
       "26   20250204-163605         0  REVERSE      car  cctv001.stream   \n",
       "28   20250204-163605         0  REVERSE      car  cctv001.stream   \n",
       "29   20250204-163605         0  REVERSE      car  cctv001.stream   \n",
       "30   20250204-163605         0  REVERSE      car  cctv001.stream   \n",
       "31   20250204-163605         0  REVERSE    truck  cctv001.stream   \n",
       "33   20250204-163605         0  REVERSE      car  cctv001.stream   \n",
       "34   20250204-163605         0  REVERSE      car  cctv001.stream   \n",
       "35   20250204-163605         0  REVERSE    truck  cctv001.stream   \n",
       "25   20250204-163605         0  REVERSE      car  cctv001.stream   \n",
       "26   20250204-163605         0  REVERSE      car  cctv001.stream   \n",
       "27   20250204-163605         0  REVERSE      car  cctv001.stream   \n",
       "\n",
       "            frame_hash  frame_num  \n",
       "67   cctv001_REVERSE_1        507  \n",
       "68   cctv001_REVERSE_1        508  \n",
       "69   cctv001_REVERSE_1        509  \n",
       "29   cctv001_REVERSE_2        123  \n",
       "30   cctv001_REVERSE_2        124  \n",
       "31   cctv001_REVERSE_2        125  \n",
       "254  cctv001_REVERSE_2       1325  \n",
       "255  cctv001_REVERSE_2       1326  \n",
       "256  cctv001_REVERSE_2       1327  \n",
       "168  cctv001_REVERSE_3        644  \n",
       "169  cctv001_REVERSE_3        645  \n",
       "170  cctv001_REVERSE_3        646  \n",
       "38   cctv001_REVERSE_4        151  \n",
       "39   cctv001_REVERSE_4        152  \n",
       "40   cctv001_REVERSE_4        153  \n",
       "73   cctv001_REVERSE_4        244  \n",
       "74   cctv001_REVERSE_4        245  \n",
       "75   cctv001_REVERSE_4        246  \n",
       "280  cctv001_REVERSE_5        996  \n",
       "281  cctv001_REVERSE_5        997  \n",
       "282  cctv001_REVERSE_5        998  \n",
       "13   cctv001_REVERSE_6         51  \n",
       "14   cctv001_REVERSE_6         52  \n",
       "15   cctv001_REVERSE_6         53  \n",
       "24   cctv001_REVERSE_7         83  \n",
       "25   cctv001_REVERSE_7         84  \n",
       "26   cctv001_REVERSE_7         85  \n",
       "28   cctv001_REVERSE_7         90  \n",
       "29   cctv001_REVERSE_7         91  \n",
       "30   cctv001_REVERSE_7         92  \n",
       "31   cctv001_REVERSE_7         93  \n",
       "33   cctv001_REVERSE_7         98  \n",
       "34   cctv001_REVERSE_7         99  \n",
       "35   cctv001_REVERSE_7        100  \n",
       "25   cctv001_REVERSE_8         88  \n",
       "26   cctv001_REVERSE_8         89  \n",
       "27   cctv001_REVERSE_8         90  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frame_hash별로 그룹핑하고, 1초 이내 5개 이상 존재하는 경우 찾기\n",
    "df_raw_reverse = df_raw[df_raw[\"event\"] == \"REVERSE\"]\n",
    "df_raw_reverse\n",
    "\n",
    "# frame_hash별로 그룹화 후 frame_num 연속성 확인\n",
    "df_filtered_reverse = pd.DataFrame()\n",
    "\n",
    "grouped = df_raw_reverse.groupby(\"frame_hash\")\n",
    "for _, group in grouped:\n",
    "    group = group.sort_values(by=\"frame_num\").reset_index(drop=True)\n",
    "    group[\"diff\"] = group[\"frame_num\"].diff().fillna(1)\n",
    "    group[\"consec_group\"] = (group[\"diff\"] != 1).cumsum()\n",
    "    valid_groups = group.groupby(\"consec_group\").filter(lambda x: len(x) >= 3)\n",
    "    df_filtered_reverse = pd.concat([df_filtered_reverse, valid_groups.drop(columns=[\"diff\", \"consec_group\"])])\n",
    "\n",
    "# 결과 출력\n",
    "df_filtered_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78a03215-1811-4426-9987-da40210176aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "origin_dir = \"/app\"\n",
    "## 최종 저장경로 설정!!\n",
    "results_dir = os.path.join(origin_dir,\"yolo_structure\",\"results\")\n",
    "## 사건파일저장\n",
    "crop_save_dir = os.path.join(results_dir,\"frame_img\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98594d8f-bb5e-4ab5-ab5a-6a057101ac0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>distance</th>\n",
       "      <th>event</th>\n",
       "      <th>detected</th>\n",
       "      <th>source_name</th>\n",
       "      <th>frame_hash</th>\n",
       "      <th>frame_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>20250203-165515</td>\n",
       "      <td>0</td>\n",
       "      <td>STOP</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_STOP_1</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>20250203-165515</td>\n",
       "      <td>0</td>\n",
       "      <td>STOP</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_STOP_1</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>20250203-165515</td>\n",
       "      <td>0</td>\n",
       "      <td>STOP</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_STOP_1</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>20250203-165515</td>\n",
       "      <td>0</td>\n",
       "      <td>STOP</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_STOP_1</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>20250203-165515</td>\n",
       "      <td>0</td>\n",
       "      <td>STOP</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_STOP_1</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>20250203-165559</td>\n",
       "      <td>0</td>\n",
       "      <td>STOP</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_STOP_5</td>\n",
       "      <td>1784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>20250203-165559</td>\n",
       "      <td>0</td>\n",
       "      <td>STOP</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_STOP_5</td>\n",
       "      <td>1785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>20250203-165559</td>\n",
       "      <td>0</td>\n",
       "      <td>STOP</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_STOP_5</td>\n",
       "      <td>1786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>20250203-165559</td>\n",
       "      <td>0</td>\n",
       "      <td>STOP</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_STOP_5</td>\n",
       "      <td>1787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>20250203-165559</td>\n",
       "      <td>0</td>\n",
       "      <td>STOP</td>\n",
       "      <td>car</td>\n",
       "      <td>cctv001.stream</td>\n",
       "      <td>cctv001_STOP_5</td>\n",
       "      <td>1788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>407 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            datetime  distance event detected     source_name      frame_hash  \\\n",
       "48   20250203-165515         0  STOP      car  cctv001.stream  cctv001_STOP_1   \n",
       "49   20250203-165515         0  STOP      car  cctv001.stream  cctv001_STOP_1   \n",
       "50   20250203-165515         0  STOP      car  cctv001.stream  cctv001_STOP_1   \n",
       "51   20250203-165515         0  STOP      car  cctv001.stream  cctv001_STOP_1   \n",
       "52   20250203-165515         0  STOP      car  cctv001.stream  cctv001_STOP_1   \n",
       "..               ...       ...   ...      ...             ...             ...   \n",
       "144  20250203-165559         0  STOP      car  cctv001.stream  cctv001_STOP_5   \n",
       "145  20250203-165559         0  STOP      car  cctv001.stream  cctv001_STOP_5   \n",
       "146  20250203-165559         0  STOP      car  cctv001.stream  cctv001_STOP_5   \n",
       "147  20250203-165559         0  STOP      car  cctv001.stream  cctv001_STOP_5   \n",
       "148  20250203-165559         0  STOP      car  cctv001.stream  cctv001_STOP_5   \n",
       "\n",
       "     frame_num  \n",
       "48         466  \n",
       "49         467  \n",
       "50         468  \n",
       "51         469  \n",
       "52         470  \n",
       "..         ...  \n",
       "144       1784  \n",
       "145       1785  \n",
       "146       1786  \n",
       "147       1787  \n",
       "148       1788  \n",
       "\n",
       "[407 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31cecbcd-e1b2-479b-8a0c-e8e2c8cd2335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/app/yolo_structure/results/frame_img/cctv001_STOP_1_466.jpg'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " os.path.join(crop_save_dir,value[\"frame_hash\"]+\"_\"+ str(value[\"frame_num\"]) +\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83c263c-9d08-45f4-a372-6bc7cb42ca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "1095/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8897ef27-238a-4455-bb8e-c5219353f5df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_468.jpg / Ollama Result: SEDAN\n",
      "Van.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_469.jpg / Ollama Result: VAN\n",
      "Bus.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_470.jpg / Ollama Result: BUS\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_665.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_666.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_667.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_689.jpg / Ollama Result: SEDAN\n",
      "Bus.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_737.jpg / Ollama Result: BUS\n",
      "Truck.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_738.jpg / Ollama Result: TRUCK\n",
      "Truck.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_740.jpg / Ollama Result: TRUCK\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_880.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_889.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_890.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_892.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_896.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_897.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_899.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_903.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_914.jpg / Ollama Result: SEDAN\n",
      "Van.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1073.jpg / Ollama Result: VAN\n",
      "Bus.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1075.jpg / Ollama Result: BUS\n",
      "Truck.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1076.jpg / Ollama Result: TRUCK\n",
      "Bus.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1077.jpg / Ollama Result: BUS\n",
      "BUS.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1078.jpg / Ollama Result: BUS\n",
      "Bus.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1081.jpg / Ollama Result: BUS\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1091.jpg / Ollama Result: SEDAN\n",
      "SUV.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1095.jpg / Ollama Result: SUV\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1110.jpg / Ollama Result: SEDAN\n",
      "Truck.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1113.jpg / Ollama Result: TRUCK\n",
      "VAN.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1169.jpg / Ollama Result: VAN\n",
      "Truck.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1170.jpg / Ollama Result: TRUCK\n",
      "Truck.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1173.jpg / Ollama Result: TRUCK\n",
      "Truck.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1174.jpg / Ollama Result: TRUCK\n",
      "Truck.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1175.jpg / Ollama Result: TRUCK\n",
      "Bus.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1176.jpg / Ollama Result: BUS\n",
      "VAN.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1209.jpg / Ollama Result: VAN\n",
      "Bus.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1210.jpg / Ollama Result: BUS\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1211.jpg / Ollama Result: SEDAN\n",
      "Truck.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1212.jpg / Ollama Result: TRUCK\n",
      "Truck.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1213.jpg / Ollama Result: TRUCK\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1214.jpg / Ollama Result: SEDAN\n",
      "VAN.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1224.jpg / Ollama Result: VAN\n",
      "Truck.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1225.jpg / Ollama Result: TRUCK\n",
      "Truck.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1226.jpg / Ollama Result: TRUCK\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1233.jpg / Ollama Result: SEDAN\n",
      "Truck.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1235.jpg / Ollama Result: TRUCK\n",
      "Truck.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1236.jpg / Ollama Result: TRUCK\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1237.jpg / Ollama Result: SEDAN\n",
      "Van.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1238.jpg / Ollama Result: VAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1241.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1254.jpg / Ollama Result: SEDAN\n",
      "Truck.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1255.jpg / Ollama Result: TRUCK\n",
      "VAN.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1256.jpg / Ollama Result: VAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1257.jpg / Ollama Result: SEDAN\n",
      "SUV.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1258.jpg / Ollama Result: SUV\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1259.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1260.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1404.jpg / Ollama Result: SEDAN\n",
      "TRUCK.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1473.jpg / Ollama Result: TRUCK\n",
      "Van.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1474.jpg / Ollama Result: VAN\n",
      "Bus.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1475.jpg / Ollama Result: BUS\n",
      "Truck.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1476.jpg / Ollama Result: TRUCK\n",
      "Truck.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1477.jpg / Ollama Result: TRUCK\n",
      "Bus.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1478.jpg / Ollama Result: BUS\n",
      "TRUCK.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1489.jpg / Ollama Result: TRUCK\n",
      "Truck.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1490.jpg / Ollama Result: TRUCK\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1491.jpg / Ollama Result: SEDAN\n",
      "Truck.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1492.jpg / Ollama Result: TRUCK\n",
      "Truck.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1493.jpg / Ollama Result: TRUCK\n",
      "Bus.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_1_1494.jpg / Ollama Result: BUS\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_565.jpg / Ollama Result: SEDAN\n",
      "Truck.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_567.jpg / Ollama Result: TRUCK\n",
      "VAN.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_583.jpg / Ollama Result: VAN\n",
      "VAN.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_584.jpg / Ollama Result: VAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_587.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_588.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_589.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_590.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_591.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_593.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_594.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_601.jpg / Ollama Result: SEDAN\n",
      "Truck.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_603.jpg / Ollama Result: TRUCK\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_604.jpg / Ollama Result: SEDAN\n",
      "Van.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_607.jpg / Ollama Result: VAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_608.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_610.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_615.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_616.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_618.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_621.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_622.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_623.jpg / Ollama Result: SEDAN\n",
      "Van.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_624.jpg / Ollama Result: VAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_626.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_639.jpg / Ollama Result: SEDAN\n",
      "SUV.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_640.jpg / Ollama Result: SUV\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_641.jpg / Ollama Result: SEDAN\n",
      "SUV.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_642.jpg / Ollama Result: SUV\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_643.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_644.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_648.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_651.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_652.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_653.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_654.jpg / Ollama Result: SEDAN\n",
      "VAN.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_659.jpg / Ollama Result: VAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_748.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_749.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_750.jpg / Ollama Result: SEDAN\n",
      "TRUCK.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_754.jpg / Ollama Result: TRUCK\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_755.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_758.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_761.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_763.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_764.jpg / Ollama Result: SEDAN\n",
      "SUV.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_765.jpg / Ollama Result: SUV\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_767.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_769.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_809.jpg / Ollama Result: SEDAN\n",
      "Bus.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1066.jpg / Ollama Result: BUS\n",
      "Bus.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1067.jpg / Ollama Result: BUS\n",
      "Truck.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1069.jpg / Ollama Result: TRUCK\n",
      "Truck.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1071.jpg / Ollama Result: TRUCK\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1073.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1074.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1076.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1130.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1131.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1132.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1133.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1134.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1137.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1138.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1139.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1140.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1141.jpg / Ollama Result: SEDAN\n",
      "Truck.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1142.jpg / Ollama Result: TRUCK\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1143.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1144.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1145.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1146.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1147.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1148.jpg / Ollama Result: SEDAN\n",
      "VAN.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1343.jpg / Ollama Result: VAN\n",
      "VAN.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1344.jpg / Ollama Result: VAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1346.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1347.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1350.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1351.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1354.jpg / Ollama Result: SEDAN\n",
      "Truck.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1355.jpg / Ollama Result: TRUCK\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1356.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1470.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1471.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1472.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1473.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1474.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_2_1475.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_3_633.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_3_634.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_3_1069.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_3_1070.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_3_1071.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_3_1073.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_3_1074.jpg / Ollama Result: SEDAN\n",
      "SUV.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_3_1371.jpg / Ollama Result: SUV\n",
      "Truck.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_3_1372.jpg / Ollama Result: TRUCK\n",
      "Truck.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_3_1373.jpg / Ollama Result: TRUCK\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_3_1375.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_3_1543.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_3_1545.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_3_1546.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_3_1547.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_3_1548.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_3_1766.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_3_1767.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_3_1768.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_3_1769.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_3_1770.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_3_1771.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_3_1774.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_4_1543.jpg / Ollama Result: SEDAN\n",
      "SUV.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_4_1545.jpg / Ollama Result: SUV\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_4_1552.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_5_1523.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_5_1525.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_5_1782.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_5_1783.jpg / Ollama Result: SEDAN\n",
      "SUV.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_5_1784.jpg / Ollama Result: SUV\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_5_1785.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_5_1786.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_5_1787.jpg / Ollama Result: SEDAN\n",
      "Sedan.\n",
      "/app/yolo_structure/results/frame_img/cctv001_STOP_5_1788.jpg / Ollama Result: SEDAN\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (200) does not match length of index (407)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcrop_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / Ollama Result: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_result\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m     llm_res_l\u001b[38;5;241m.\u001b[39mappend(final_result)\n\u001b[0;32m---> 26\u001b[0m df_filtered_stop[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm_res\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m llm_res_l\n\u001b[1;32m     27\u001b[0m df_filtered_stop\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/frame.py:4311\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   4309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4310\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 4311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item(key, value)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/frame.py:4524\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4515\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4516\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4517\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4522\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4523\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4524\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sanitize_column(value)\n\u001b[1;32m   4526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4527\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4528\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4529\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m   4530\u001b[0m     ):\n\u001b[1;32m   4531\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4532\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/frame.py:5266\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   5265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 5266\u001b[0m     com\u001b[38;5;241m.\u001b[39mrequire_length_match(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   5267\u001b[0m arr \u001b[38;5;241m=\u001b[39m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   5268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5269\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[1;32m   5270\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5273\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[1;32m   5274\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pandas/core/common.py:573\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (200) does not match length of index (407)"
     ]
    }
   ],
   "source": [
    "llm_res_l = []\n",
    "for index,value in df_filtered_stop.iterrows():\n",
    "    if value[\"detected\"] !=\"car\":\n",
    "        llm_res_l.append(value[\"detected\"])\n",
    "        continue\n",
    "    try:\n",
    "        crop_filename = os.path.join(crop_save_dir,value[\"frame_hash\"]+\"_\"+ str(value[\"frame_num\"]) +\".jpg\")\n",
    "        res = ollama.chat(\n",
    "            model= \"llama3.2-vision:11b\",\n",
    "            messages=[\n",
    "                {\n",
    "                    'role': 'user',\n",
    "                    'content': \"tell me what is in this image. Answer only one in [SEDAN/SUV/VAN/TRUCK/BUS] answer in one word\",\n",
    "                    'images': [crop_filename]\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        print(res['message']['content'])\n",
    "    except:\n",
    "       continue\n",
    "\n",
    "    final_result = res['message']['content'].upper().replace(\".\",\"\").replace(\" \",\"\")\n",
    "    print(f\"{crop_filename} / Ollama Result: {final_result}\")\n",
    "    llm_res_l.append(final_result)\n",
    "df_filtered_stop[\"llm_res\"] = llm_res_l\n",
    "df_filtered_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecebb7a9-233f-4291-bbcd-75066492eb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_res_l = []\n",
    "for index,value in df_filtered_reverse.iterrows():\n",
    "    if value[\"detected\"] !=\"car\":\n",
    "        llm_res_l.append(value[\"detected\"])\n",
    "        continue\n",
    "   \n",
    "    crop_filename = os.path.join(crop_save_dir,value[\"frame_hash\"]+\"_\"+ str(value[\"frame_num\"]) +\".jpg\")\n",
    "    res = ollama.chat(\n",
    "        model= \"llama3.2-vision:11b\",\n",
    "        messages=[\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': \"tell me what is in this image. Answer only one in [SEDAN/SUV/VAN/TRUCK/BUS] answer in one word\",\n",
    "                'images': [crop_filename]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(res['message']['content'])\n",
    "\n",
    "    final_result = res['message']['content'].upper().replace(\".\",\"\").replace(\" \",\"\")\n",
    "    print(f\"{crop_filename} / Ollama Result: {final_result}\")\n",
    "    llm_res_l.append(final_result)\n",
    "df_filtered_reverse[\"llm_res\"] = llm_res_l\n",
    "df_filtered_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699a5292-a282-4233-8c54-1543468f69ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
